<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>mactql的小站</title>
  
  
  <link href="https://mactql.github.io/atom.xml" rel="self"/>
  
  <link href="https://mactql.github.io/"/>
  <updated>2022-02-23T13:41:28.500Z</updated>
  <id>https://mactql.github.io/</id>
  
  <author>
    <name>mactql</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据缓存机制</title>
    <link href="https://mactql.github.io/posts/569534204.html"/>
    <id>https://mactql.github.io/posts/569534204.html</id>
    <published>2022-02-23T08:09:00.000Z</published>
    <updated>2022-02-23T13:41:28.500Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据缓存机制"><a href="#数据缓存机制" class="headerlink" title="数据缓存机制"></a>数据缓存机制</h1><h2 id="数据缓存机制是什么？"><a href="#数据缓存机制是什么？" class="headerlink" title="数据缓存机制是什么？"></a>数据缓存机制是什么？</h2><p><strong>在执行</strong><a href="https://www.wolai.com/8uyJQkYrRzBxv16p1Ts7Wa">数据操作算子</a><strong>的过程中，可能会对一些数据多次访问，需要花费大量时间。Spark提供了数据缓存机制，可以把这些数据缓存起来，加快处理速度。</strong></p><p><strong>我们来看一个具体的例子：</strong></p><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/image.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/image.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><strong>之前我们学过了job是根据action()算子来提交的，回顾一下之前学过的内容：</strong></p><ul><li><a href="https://www.wolai.com/s3xt57rWrZURyDgsku2P3u">注意：spark会按照顺序为每个action()算子生成一个job，这个job的逻辑处理流程是从输入数据到最后action()操作</a></li><li><a href="https://www.wolai.com/hpXVx28eQu6GBCmjMDauDa">action()算子</a></li></ul><p><strong>代码中的两个foreach的action操作会生成两个job提交，每一个job的逻辑处理流程都是从inputRDD到mappedRDD到foreach。但inputRDD到mappedRDD的过程实际上被计算了两次，可以将mappedRDD缓存起来，这样第二个job就可以直接从mappedRDD开始计算。</strong></p><h2 id="哪些数据需要被缓存呢？"><a href="#哪些数据需要被缓存呢？" class="headerlink" title="哪些数据需要被缓存呢？"></a>哪些数据需要被缓存呢？</h2><p><strong>一般满足以下两个要求：</strong></p><ul><li><strong>会被多个job重复使用的数据</strong></li><li><strong>数据量不是太大。因为cache缓存就是把数据放到内存中，如果数据量太大，会导致内存不足。虽然可以用persist放到磁盘中，但是磁盘I/O代价比较高，速度可能还不如不缓存</strong></li></ul><h2 id="怎样使用数据缓存呢？"><a href="#怎样使用数据缓存呢？" class="headerlink" title="怎样使用数据缓存呢？"></a>怎样使用数据缓存呢？</h2><p><strong>书中这里描述了两个方法，一个是</strong>**<code>RDD.cache()</code><strong><strong>，一个是</strong></strong><code>RDD.persist(缓存级别)</code>**<strong>。</strong></p><p><strong>上面图中就展示了cache的使用案例</strong></p><ul><li><strong>这里需要注意，cache()操作表示将数据直接写入内存，但同</strong><strong><a href="https://www.wolai.com/xsDB3fVnER5NpKqhHUpdJH">transformation()是lazy操作，不会立即执行，需要等action()提交job后，job执行任务时才会执行</a></strong></li></ul><p><strong>一般情况用cache缓存进内存就可以了，persist可满足其他的缓存需求(存磁盘、序列化、备份)，看下图了解即可</strong></p><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/image_1.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/image_1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据缓存机制&quot;&gt;&lt;a href=&quot;#数据缓存机制&quot; class=&quot;headerlink&quot; title=&quot;数据缓存机制&quot;&gt;&lt;/a&gt;数据缓存机制&lt;/h1&gt;&lt;h2 id=&quot;数据缓存机制是什么？&quot;&gt;&lt;a href=&quot;#数据缓存机制是什么？&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark中的Shuffle机制</title>
    <link href="https://mactql.github.io/posts/2064420061.html"/>
    <id>https://mactql.github.io/posts/2064420061.html</id>
    <published>2022-02-18T14:09:00.000Z</published>
    <updated>2022-02-18T14:16:09.360Z</updated>
    
    <content type="html"><![CDATA[<p><strong>在之前章节，我们了解了Spark如何将逻辑处理流程转化为物理执行计划，也学习了如何执行计算任务(task)，但是没有详细讨论上下游stage之间和不同节点上的task之间是如何传递数据的，这个数据传递过程实际就是Shuffle机制。</strong><br><a name="wR7ED"></a></p><h2 id="什么是Shuffle机制？"><a href="#什么是Shuffle机制？" class="headerlink" title="什么是Shuffle机制？"></a>什么是Shuffle机制？</h2><p><strong>Shuffle机制分为两个阶段，Shuffle Write阶段(map端) 和 Shuffle Read(reduce端)</strong><br /><strong>Write处理上游stage输出数据分区，Read从上游stage获取和组织数据并为后续操作提供数据</strong><br><a name="d4Opd"></a></p><h3 id="第一个问题，如何确定上游stage的输出数据输出到下游的哪个分区？"><a href="#第一个问题，如何确定上游stage的输出数据输出到下游的哪个分区？" class="headerlink" title="第一个问题，如何确定上游stage的输出数据输出到下游的哪个分区？"></a>第一个问题，如何确定上游stage的输出数据输出到下游的哪个分区？</h3><ul><li><strong>先确定下游的分区数，用户没有指定就是上游stage最后一个RDD的最大分区数</strong></li><li><strong>如何确定输出到哪个分区呢？根据上游输出的&lt;K,V&gt; 中的key计算partitionID，比如下图分两个分区，那就可以hash(Key)%2得到partitionID，然后直接将record输出到对应下游partitionID的分区中即可</strong></li></ul><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/0.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><a name="e1rZW"></a></p><h3 id="第二个问题，如何获取上游不同task的输出数据并实现聚合操作？"><a href="#第二个问题，如何获取上游不同task的输出数据并实现聚合操作？" class="headerlink" title="第二个问题，如何获取上游不同task的输出数据并实现聚合操作？"></a>第二个问题，如何获取上游不同task的输出数据并实现聚合操作？</h3><ul><li><strong>首先举个例子，groupByKey()需要把从不同task得到的&lt;K,V&gt;聚合成&lt;K,List(V)&gt;</strong></li><li><strong>方法是两步聚合，先把从不同task得到的&lt;K,V&gt;放到hashmap中，然后再进行聚合计算，如下图所示</strong></li></ul><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/1.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>优化：所有的record都会被放入hashmap，为了减少空间占用，对于reduceByKey等需要聚合计算的算子采用在线聚合，在每个record加入hashmap同时使用func()更新聚合结果，如上图所示</strong></li></ul><p><a name="KcaON"></a></p><h2 id="另外两个Shuffle的重要功能："><a href="#另外两个Shuffle的重要功能：" class="headerlink" title="另外两个Shuffle的重要功能："></a>另外两个Shuffle的重要功能：</h2><h3 id="combine功能："><a href="#combine功能：" class="headerlink" title="combine功能："></a>combine功能：</h3><p><strong>我们在前面章节中了解过，为了减少shuffle的数据量，在shuffle之前先进行combine()操作，实际上和shuffleRead一样，利用HashMap进行combine，然后对hashmap的record进行分区计算，然后输出到相应下游分区中</strong><br><a name="Xcq21"></a></p><h3 id="sort功能："><a href="#sort功能：" class="headerlink" title="sort功能："></a>sort功能：</h3><p><strong>例如sortByKey()需要sort功能，shuffleRead阶段需要把上游数据放在一起进行全局排序。在上游可以先排一下，可以减少read端排序的复杂度，而且上游并行起来肯定比下游一个任务快</strong><br><a name="HACcV"></a></p><h3 id="内存-磁盘混合存储功能："><a href="#内存-磁盘混合存储功能：" class="headerlink" title="内存+磁盘混合存储功能："></a>内存+磁盘混合存储功能：</h3><p><strong>试想一下，在shuffle的过程中我们使用hashmap进行聚合计算，当数据量很大的时候内存可能会溢出</strong><br /><strong>这时，采用内存+磁盘混合存储，先在内存(hashmap)中聚合，内存不足就溢出到磁盘，继续处理新的数据，再下一次数据操作之前对磁盘和内存中的数据再次聚合，具体做法后面细说</strong><br /><strong>​</strong><br /></p><h2 id="Shuffle框架设计"><a href="#Shuffle框架设计" class="headerlink" title="Shuffle框架设计"></a>Shuffle框架设计</h2><p><strong>下图所示的是一些常用的操作算子的计算需求</strong><br /><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/2.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h3 id="Shuffle-Write的框架设计"><a href="#Shuffle-Write的框架设计" class="headerlink" title="Shuffle Write的框架设计"></a>Shuffle Write的框架设计</h3><p><strong>如下图所示，计算顺序为map()输出-&gt;数据聚合-&gt;sort-&gt;分区</strong><br /><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/3.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br /><strong>下面详细Spark如何针对不同情况构建Write方式</strong><br><a name="iO5vx"></a></p><h4 id="不需要在map端聚合和排序的情况-join、groupByKey、sortByKey等"><a href="#不需要在map端聚合和排序的情况-join、groupByKey、sortByKey等" class="headerlink" title="不需要在map端聚合和排序的情况(join、groupByKey、sortByKey等)"></a>不需要在map端聚合和排序的情况(join、groupByKey、sortByKey等)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/4.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>只需要实现分区功能，map依次输出record，然后计算partitionID，为每个PID分配一个buffer，spark根据PID把record写到不同的buffer中，buffer满了就写磁盘的分区文件中</strong></li><li><strong>优缺点：速度快，但是分区越多buffer越多，内存消耗大</strong></li></ul><p><a name="bIWio"></a></p><h4 id="不需要map端聚合，但需要排序的情况-目前这样的算子"><a href="#不需要map端聚合，但需要排序的情况-目前这样的算子" class="headerlink" title="不需要map端聚合，但需要排序的情况(目前这样的算子)"></a>不需要map端聚合，但需要排序的情况(目前这样的算子)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/5.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/5.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>建立一个Array(图中PartitionedPairBuffer)来存放map()输出的record，并转化为&lt;(PID,K),V&gt;的record存储，然后按照PID和Key进行排序</strong></li><li><strong>优缺点：用一个Array结构可大可小可以排序，但排序时间长</strong></li></ul><p><a name="ZdHnO"></a></p><h4 id="需要map端聚合，排序可选的情况-distinct、reduceByKey、aggregateByKey等"><a href="#需要map端聚合，排序可选的情况-distinct、reduceByKey、aggregateByKey等" class="headerlink" title="需要map端聚合，排序可选的情况(distinct、reduceByKey、aggregateByKey等)"></a>需要map端聚合，排序可选的情况(distinct、reduceByKey、aggregateByKey等)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/6.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>先用类似HashMap的数据结构   <em>(PartitionedAppendOnlyMap，实际上就是用Array实现的只能添加或修改的hashmap，因为是Array所以也可进行快排等算法)</em>_   _进行combine在线聚合，来一条record就聚合一条record。如果需要排序(图中下面情况)就按照PID和Key排，不需要就按PID排序，然后输出到磁盘对应的分区文件中</strong></li><li><strong>优缺点：数据量可大可小，PartitionedAppedOnlyMap很牛逼，又能在线聚合又能排序，最后只输出一个文件省资源</strong></li></ul><p><a name="cVJ1g"></a></p><h3 id="Shuffle-Read的框架设计"><a href="#Shuffle-Read的框架设计" class="headerlink" title="Shuffle Read的框架设计"></a>Shuffle Read的框架设计</h3><p><strong>如下图所示，计算顺序为数据获取-&gt;聚合-&gt;排序</strong><br /><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/7.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/7.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br /><strong>下面详细Spark如何针对不同情况构建Read方式</strong><br><a name="eXRUS"></a></p><h4 id="reduce端不需要聚合和排序的情况-partitionBy"><a href="#reduce端不需要聚合和排序的情况-partitionBy" class="headerlink" title="reduce端不需要聚合和排序的情况(partitionBy)"></a>reduce端不需要聚合和排序的情况(partitionBy)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/8.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/8.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>开一个buffer，然后收集各个map task输出的record，然后进行后续操作</strong></li><li><strong>优缺点：内存消耗很小</strong></li></ul><p><a name="MsWmj"></a></p><h4 id="reduce端不需要聚合，但需要排序的情况-sortByKey、sortBy等"><a href="#reduce端不需要聚合，但需要排序的情况-sortByKey、sortBy等" class="headerlink" title="reduce端不需要聚合，但需要排序的情况(sortByKey、sortBy等)"></a>reduce端不需要聚合，但需要排序的情况(sortByKey、sortBy等)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/9.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/9.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>获取数据还是通过一个buffer，然后跟write端一样，用PartitionedPairBuffer存数据组成&lt;(PID,K),V&gt;，然后按照Key排序，然后就是后续操作</strong></li><li><strong>优缺点：数据量可大可小，Array和磁盘一起用，但排序时间长</strong></li></ul><p><a name="Od2UQ"></a></p><h4 id="reduce端需要聚合，排序可选的情况-join、groupByKey、reduceByKey等"><a href="#reduce端需要聚合，排序可选的情况-join、groupByKey、reduceByKey等" class="headerlink" title="reduce端需要聚合，排序可选的情况(join、groupByKey、reduceByKey等)"></a>reduce端需要聚合，排序可选的情况(join、groupByKey、reduceByKey等)</h4><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/10.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E4%B8%AD%E7%9A%84Shuffle%E6%9C%BA%E5%88%B6/10.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>用类似HashMap的结构   _ ( ExternalAppendOnlyMap，实际就是在AppendOnlyMap基础上实现溢写磁盘聚合的功能，若要排序则不断维护最后全局排序 ) _   进行聚合，需要排序就排个序。支持扩容和溢写，最后把磁盘+内存的数据进行聚合，然后进行后续操作</strong></li><li><strong>优缺点：边获取数据边聚合，效率高，但需要在内存中聚合，溢写磁盘的数据需要再次在Array中聚合，内存消耗大</strong></li></ul><h2 id="与MapReduce的Shuffle机制对比"><a href="#与MapReduce的Shuffle机制对比" class="headerlink" title="与MapReduce的Shuffle机制对比"></a>与MapReduce的Shuffle机制对比</h2><ul><li><strong>MR强制按照Key排序，但groupByKey不需要排序，浪费性能，Spark为不同情况设计不同方案</strong></li><li><strong>MR聚合前先把数据全部存好才能进行聚合，Spark采用AppendOnlyMap在线聚合，来一条计算一条，省时省空间</strong></li><li><strong>MR在map端，m个map和n个reduce会产生m*n个临时文件_（《MapReduce工作机制》中有详细讲解）_，Spark输出按照PID排序的数据，只输出一个文件</strong></li></ul><p>​</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;在之前章节，我们了解了Spark如何将逻辑处理流程转化为物理执行计划，也学习了如何执行计算任务(task)，但是没有详细讨论上下游stage之间和不同节点上的task之间是如何传递数据的，这个数据传递过程实际就是Shuffle机制。&lt;/strong&gt;&lt;br&gt;</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark物理执行计划</title>
    <link href="https://mactql.github.io/posts/2386432583.html"/>
    <id>https://mactql.github.io/posts/2386432583.html</id>
    <published>2022-02-17T13:06:00.000Z</published>
    <updated>2022-02-17T13:19:37.880Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本章的核心问题是如何将逻辑处理流程转化为物理执行计划，下面将详细讲解，请读者结合大数据处理框架图进行学习</strong><br><a name="bnRhi"></a></p><h2 id="物理执行计划生成方法："><a href="#物理执行计划生成方法：" class="headerlink" title="物理执行计划生成方法："></a>物理执行计划生成方法：</h2><ul><li><strong>Spark采用3个步骤来生成物理执行计划，下面将详细介绍这三个步骤</strong><ol><li><strong>根据action()操作顺序将应用划分为作业(job)</strong><ul><li><strong>注意：spark会按照顺序为每个action()算子生成一个job，这个job的逻辑处理流程是从输入数据到最后action()操作</strong></li></ul></li><li><strong>根据shuffle依赖(宽依赖)将job划分为执行阶段(stage)</strong><ul><li><strong>注意：划分stage是从后往前的，遇到窄依赖就纳入并继续往前，遇到宽依赖就停止并划分为一个stage。如下图所示，先从result开始往前，到CoGroupedRDD有一个宽依赖和一个窄依赖，划分开，然后继续对另一个窄依赖回溯，到shuffledRDD宽依赖结束得到stage2。同理向前回溯，得到stage1和0</strong></li><li><strong>常见的shuffle依赖有：partitionBy，group/reduce/aggregate/..ByKey，coalesce(shuffle=true)，repartition，sortBy，distinct等</strong></li></ul></li><li><strong>根据分区计算将各个stage划分为计算任务(task)</strong><ul><li><strong>注意：每个stage的最后一个RDD看有多少个分区就生成多少个task。如下图所示，stage0生成3个task，stage1生成4个task，stage3生成3个task</strong></li></ul></li></ol></li></ul><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E7%89%A9%E7%90%86%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/0.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E7%89%A9%E7%90%86%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>总结：Spark可以将一个应用的逻辑处理流程根据action()生成多个job，然后根据job逻辑流程中的宽依赖划分成多个stage，然后根据每个stage最后的RDD分区个数生成多个task，然后同一个阶段的task可以分发到不同的机器上并行执行</strong></li></ul><h2 id="一些需要注意的细节"><a href="#一些需要注意的细节" class="headerlink" title="一些需要注意的细节"></a>一些需要注意的细节</h2><h3 id="并行细节："><a href="#并行细节：" class="headerlink" title="并行细节："></a>并行细节：</h3><ol><li><strong>job的提交顺序看action()的调用顺序</strong></li><li><strong>stage的执行顺序看job内的划分，不依赖上游数据的可以并行，依赖上游stage数据的需要上游执行完才可以执行</strong></li><li><strong>同一个stage的task可以在不同机器上并行处理</strong></li></ol><h3 id="task内部数据存储与计算细节："><a href="#task内部数据存储与计算细节：" class="headerlink" title="task内部数据存储与计算细节："></a>task内部数据存储与计算细节：</h3><ul><li><strong>当上游分区与下游分区内的record是一一对应的关系，采用”流水线”式的计算。例如rdd.map().filter()，内存里一个record进来把map和filter都算完后再读取下一条record。这样就不用在map和filter之间存储中间数据，减少内存使用空间</strong></li><li><strong>当然例如mapPartition这种需要一次性把数据弄到内存的不能使用“流水线”式的计算</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;本章的核心问题是如何将逻辑处理流程转化为物理执行计划，下面将详细讲解，请读者结合大数据处理框架图进行学习&lt;/strong&gt;&lt;br&gt;&lt;a name=&quot;bnRhi&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;物理执行计划生成方法：&quot;&gt;&lt;a href=&quot;#物理执行计划生成</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark常用的数据操作算子</title>
    <link href="https://mactql.github.io/posts/3129130272.html"/>
    <id>https://mactql.github.io/posts/3129130272.html</id>
    <published>2022-02-16T02:30:00.000Z</published>
    <updated>2022-02-17T12:03:32.975Z</updated>
    
    <content type="html"><![CDATA[<hr><p><a name="Xl38X"></a></p><h2 id="常用Transformations-操作"><a href="#常用Transformations-操作" class="headerlink" title="常用Transformations()操作"></a>常用Transformations()操作</h2><table><thead><tr><th><strong>rdd2 = rdd1.map(func)</strong></th><th><strong>对rdd1中的每个元素进行处理和输出</strong></th><th><strong>P51</strong></th></tr></thead><tbody><tr><td>rdd2 = rdd1.mapValues(func)</td><td>对rdd1中的每个&lt;K,V&gt;，对每个V进行处理和输出</td><td>P51</td></tr><tr><td><strong>rdd2 = rdd1.filter(func)</strong></td><td><strong>对rdd1中的每个元素过滤出符合func的元素组成新RDD</strong></td><td><strong>P52</strong></td></tr><tr><td>rdd2 = rdd1.filterByRange(a,b)</td><td>对rdd1中的每个元素过滤出在(a,b)范围内的元素组成新RDD</td><td>P52</td></tr><tr><td><strong>rdd2 = rdd1.flatMap(func)</strong></td><td><strong>对rdd1中的每个元素进行处理，再平坦后组成新RDD</strong></td><td><strong>P53</strong></td></tr><tr><td>rdd2 = rdd1.flatMapValues(func)</td><td>对rdd1中的每个&lt;K,V&gt;，对V进行flatMap操作形成新RDD</td><td>P53</td></tr><tr><td><strong>rdd2 = rdd1.sample(true,0.5)</strong></td><td><strong>对rdd1中的数据进行抽样，参数：(放回抽样，抽样比例，随机数种子)</strong></td><td><strong>P54-55</strong></td></tr><tr><td>rdd2 = rdd1.sampleByKey(true,map)</td><td>对rdd1中的数据根据map进行抽样，map为key和抽样比例的映射</td><td>P54-55</td></tr><tr><td><strong>rdd2 = rdd1.mapPartitions(func)</strong></td><td><strong>对rdd1中的每个分区进行一次性处理，处理完毕后输出</strong></td><td><strong>P55</strong></td></tr><tr><td>rdd2 = rdd1.mapPartitionsWithIndex(func)</td><td>同mapPartitions，区别在新RDD带有索引，表示对应哪个分区</td><td>P56</td></tr><tr><td>rdd2 = rdd1.partitionBy(Partitioner)<br />​<br /></td><td>对rdd1重新设置分区数，可设置hash划分/区域划分等方式<br />Partitioner可以是new HashPartitioner(numPartitions)</td><td>P58</td></tr><tr><td><strong>rdd2 = rdd1.groupByKey([numPartition])</strong></td><td><strong>对rdd1中的&lt;K,V&gt;按照key聚合在一起，形成&lt;K,List(V)。参数默认rdd1分区数可指定。若需shuffle，一般换用reduceByKey()</strong></td><td><strong>P59-60</strong></td></tr><tr><td><strong>rdd2 = rdd1.reduceByKey(func,[numPartition])</strong></td><td><strong>同groupByKey对相同key的value进行聚合，区别在聚合过程使用func对value融合计算，在shuffle情况下先对rdd每个分区combine再reduce聚合计算，效率比groupByKey高</strong></td><td><strong>P60-61</strong></td></tr><tr><td><strong>rdd2 = rdd1.aggregateByKey(zerovalue)(seqOp,combOp,[numPartition])</strong></td><td><strong>更通用的聚合操作，可在combine和reduce使用不同的操作，同时可设置初始值。首先对rdd每个分区用seqOp作combine再用combOp作reduce聚合计算</strong></td><td><strong>P62-63</strong></td></tr><tr><td><strong>rdd3 = rdd1.cogroup(rdd2,[numPartition])</strong></td><td><strong>将RDD1中的&lt;K,V&gt;和RDD2中的&lt;K,W&gt;按照key聚合在一起，形成&lt;K，List<V>，List<W>&gt;</strong></td><td><strong>P66</strong></td></tr><tr><td><strong>rdd3 = rdd1.join(rdd2)</strong></td><td><strong>将RDD1中的&lt;K,V&gt;和RDD2中的&lt;K,W&gt;按照key关联在一起，形成&lt;K，(V，W)&gt;，舍去单独K的元祖</strong></td><td><strong>P68</strong><br /></td></tr><tr><td><strong>rdd3 = rdd1.cartesian(rdd2)</strong></td><td><strong>计算两个RDD的笛卡尔积，返回所有可能的配对元祖，注意是多对多的窄依赖</strong></td><td><strong>P70-71</strong></td></tr><tr><td><strong>rdd2 = rdd1.sortByKey(true,[numPartitioin])</strong></td><td><strong>对rdd1中的&lt;K,V&gt;按照Key排序，true为升序false降序</strong></td><td><strong>P71</strong></td></tr><tr><td><strong>rdd2 = rdd1.distinct([numPartition])</strong></td><td><strong>对rdd1中的元素进行去重</strong></td><td><strong>P76</strong></td></tr><tr><td><strong>rdd3 = rdd1.union(rdd2)</strong></td><td><strong>将rdd1和rdd2中的元素合并在一起</strong></td><td><strong>P77-78</strong></td></tr><tr><td>rdd2 = rdd1.coalesce(numPartition,[true])</td><td>将rdd的分区个数升高或降低为numPartition，若想要增加分区或者想要减少分区且不希望造成数据倾斜，第二个参数需要设置为true来启动shuffle，或使用repartition</td><td>P73-74</td></tr><tr><td>rdd2 = rdd1.repartition(numPartition)</td><td>和coalesce(numPartition,true)完全相同</td><td>P74</td></tr><tr><td>repartitionAndSortWithinPartitions(partitioner)</td><td>等同于repartition()+sortByKey()，但效率更高</td><td>P74-75</td></tr><tr><td>rdd3 = rdd1.intersection(rdd2)</td><td>求出两个RDD的交集，即共同元素组成rdd3</td><td>P75</td></tr><tr><td>rdd3 = rdd1.zip(rdd2)</td><td>将rdd1的元素和rdd2元素连接在一起，rdd1中为K，rdd2为V，组成&lt;K,V&gt;</td><td>P78-79</td></tr><tr><td>rdd2 = rdd1.zipWithIndex()</td><td>对rdd1的数据从0开始递增编号&lt;k,0&gt;、&lt;k,1&gt;….</td><td>P81-82</td></tr><tr><td>rdd3 = rdd1.substract/substractByKey(rdd2)</td><td>计算在rdd1中的元素/key而不在rdd2中的元素</td><td>P82-83</td></tr><tr><td>rdd2 = rdd1.sortBy(func)</td><td>同sortByKey对元素排序，区别在可实现对value排序</td><td>P84-85</td></tr><tr><td>rdd2 = rdd1.glom()</td><td>将rdd1中每个分区的元素合并到List中</td><td>P85</td></tr></tbody></table><p><a name="Z08gt"></a></p><h2 id="常用action-操作"><a href="#常用action-操作" class="headerlink" title="常用action()操作"></a>常用action()操作</h2><table><thead><tr><th><strong>val res = rdd.count()/</strong><br /><strong>countByKey()/</strong><br /><strong>countByValue()</strong></th><th><strong>count统计rdd中元素个数，返回Long类型</strong><br /><strong>countByKey统计rdd中key出现的次数，返回Map[K,long]</strong><br /><strong>countByValue统计每个元素出现次数，返回Map[T,long]</strong></th><th><strong>P86</strong></th></tr></thead><tbody><tr><td><strong>val res = rdd.collect()/</strong><br /><strong>collectAsMap()</strong></td><td><strong>collect将rdd中元素收集到Driver端得到Array[T]</strong><br /><strong>AsMap将rdd中&lt;K,V&gt;收集到Driver端得到Map[K,V]</strong></td><td><strong>P88</strong></td></tr><tr><td><strong>rdd.foreach(func)/</strong><br /><strong>foreachPartition(func)</strong></td><td><strong>foreach将rdd每个元素按照func处理</strong><br /><strong>foreachPartition将rdd的每个分区的数据按照func处理</strong></td><td><strong>P88</strong></td></tr><tr><td><strong>rdd.reduce(func)/</strong><br /><strong>aggregate(zeroValue)(seqOp,combOp)</strong></td><td><strong>reduce同reduceByKey，对元素按照func聚合计算</strong><br /><strong>aggregate同aggregateByKey，比reduce更一般的聚合</strong></td><td><strong>P89</strong></td></tr><tr><td><strong>rdd.take(num)：Array[T]</strong><br /><strong>rdd.first()：T</strong><br /><strong>rdd.takeOrdered(num)/top(num)</strong><br /><strong>rdd.max()/min()</strong></td><td><strong>将rdd中前num个元素取出组成数组返回</strong><br /><strong>取出第一个元素，类似take(1)</strong><br /><strong>取出rdd中最小/最大的num个元素，要求元素可以比较</strong><br /><strong>计算出rdd中最大/最小的元素</strong></td><td><strong>P95</strong></td></tr><tr><td><strong>rdd.isEmpty()</strong></td><td><strong>判断rdd是否为空，空返回true</strong></td><td><strong>P96</strong></td></tr><tr><td><strong>rdd.saveAsTextFile/saveAsOjbectFile/saveAsSequenceFile/saveAsHadoopFile(Path)</strong></td><td><strong>将rdd保存为文本文件/序列化对象文件/sequenceFile文件，文件里存放序列化对象/HadoopHdfs支持的文件</strong></td><td><strong>​</strong><br /></td></tr><tr><td><strong>rdd.lookup(Key)：Seq[V]</strong></td><td><strong>找出rdd中包含特定key的value，组成List</strong><br /><strong>实际上等同于filter+map+collect</strong></td><td><strong>P97</strong></td></tr></tbody></table><p><a name="C5And"></a></p><h2 id="几个比较难的算子需要分析一下："><a href="#几个比较难的算子需要分析一下：" class="headerlink" title="几个比较难的算子需要分析一下："></a>几个比较难的算子需要分析一下：</h2><p><a name="WqG7e"></a></p><h3 id="flatMap-和Map-容易混淆："><a href="#flatMap-和Map-容易混淆：" class="headerlink" title="flatMap()和Map()容易混淆："></a>flatMap()和Map()容易混淆：</h3><ul><li><strong>对于一维数组来说，map和flatmap没有区别。对于多维数组，例如RDD(List(1,2),List(3,4)…)，如果想要每个List中的元素+1，则map算子对每个元素+1返回RDD(List(2,3),List(4,5))；而flatmap是先map后flat，故他会先得到map的结果，然后将其平坦化，得到RDD(2,3,4,5)</strong></li></ul><p><a name="Rfj0n"></a></p><h3 id="map-和mapPartition-的区别："><a href="#map-和mapPartition-的区别：" class="headerlink" title="map()和mapPartition()的区别："></a>map()和mapPartition()的区别：</h3><ul><li><strong>例如rdd中某个分区的元素是(1,2,3)，rdd.map()就相当于</strong><code>for&#123; res = func(arr(i)); output(res);&#125;</code><strong>，也就是处理完一个元素，就输出出去；而mapPartition是一次性处理完所有数据，再输出，相当于</strong><code>res = func(arr);output(res);</code></li></ul><p><a name="T4SCO"></a></p><h3 id="groupByKey-和reduceByKey-aggregateByKey-的使用场景："><a href="#groupByKey-和reduceByKey-aggregateByKey-的使用场景：" class="headerlink" title="groupByKey()和reduceByKey()/aggregateByKey()的使用场景："></a>groupByKey()和reduceByKey()/aggregateByKey()的使用场景：</h3><ul><li><strong>groupByKey是把rdd1中的&lt;K,V&gt;按照key聚合在一起，形成&lt;K,List(V)。问题在于groupByKey生成RDD的过程中，如果rdd1没有提前使用partitionBy()根据hash划分，会导致shuffle产生大量中间数据、占用内存大的问题，多数情况会使用reduceByKey()</strong></li><li><strong>reduceByKey为了解决groupByKey的shuffle问题，在shuffle之前，先对每个分区的数据进行一个本地化的combine()聚合操作，之后再进行同样的reduce聚合计算，这样减少了数据传输量和内存用量，效率比groupByKey()高</strong></li><li><strong>aggregateByKey是一个通用的聚合操作，当我们想让reduceByKey的combine()和redece()使用不同的聚合函数，例如combine()的时候用sum(),reduce用max()，reduceByKey就不满足要求了，这时使用aggregateByKey(zeroValue)(seqOp,combOp,[numPartitions])，seqOp是combine()时的聚合函数，combOp是在reduce()阶段用的聚合函数，zeroValue是进行combine聚合计算若需要的初始值。具体使用案例如下，</strong><code>val resRDD = rdd1.aggregateByKey(&quot;x&quot;,2)(_+&quot;_&quot;+_ , _+&quot;@&quot;+_)</code><strong>，也就是说在combine阶段使用初始值x和下划线对分区内相同key的value进行连接，在reduce后用@连接相同key的元素</strong></li></ul><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E7%AE%97%E5%AD%90/0.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E7%AE%97%E5%AD%90/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><a name="F7uQ9"></a></p><h3 id="cogroup-、join-、cartesian-容易混淆："><a href="#cogroup-、join-、cartesian-容易混淆：" class="headerlink" title="cogroup()、join()、cartesian()容易混淆："></a>cogroup()、join()、cartesian()容易混淆：</h3><ul><li><strong>比如rdd1&lt;K,V&gt;，rdd2&lt;K,W&gt;</strong></li><li><strong>cogroup是把相同key的value聚合在一起，组成&lt;K,(V1,V2,….),(W1,W2,….)&gt;</strong></li><li><strong>join是把相同key的value关联在一起，组成&lt;K,(V1,V2,…,W1,W2,…)&gt;</strong></li><li><strong>cartesian是计算两个rdd的笛卡尔积，两个rdd中分区元素的两两组合。例如rdd1=(分区1，分区2),rdd2=(分区3，分区4)，那么cartesian后得到rdd3=(分区1<em>分区3),(分区1</em>分区4),(分区2<em>分区3),(分区2</em>分区4)，如下图所示：</strong></li></ul><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E7%AE%97%E5%AD%90/1.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E5%B8%B8%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E7%AE%97%E5%AD%90/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;hr&gt;
&lt;p&gt;&lt;a name=&quot;Xl38X&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;常用Transformations-操作&quot;&gt;&lt;a href=&quot;#常用Transformations-操作&quot; class=&quot;headerlink&quot; title=&quot;常用Transformations()</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark逻辑处理流程</title>
    <link href="https://mactql.github.io/posts/3742403319.html"/>
    <id>https://mactql.github.io/posts/3742403319.html</id>
    <published>2022-02-13T07:30:00.000Z</published>
    <updated>2022-02-13T08:25:56.851Z</updated>
    
    <content type="html"><![CDATA[<p><a name="uidqd"></a></p><h2 id="逻辑处理流程四部分："><a href="#逻辑处理流程四部分：" class="headerlink" title="逻辑处理流程四部分："></a>逻辑处理流程四部分：</h2><ol><li><strong>数据源：从hdfs，hbase甚至内存里的数据结构，流式处理还可以是网络流</strong></li><li><strong>数据模型：</strong><ul><li><strong>MR里面是&lt;K,V&gt;形式的，只能map(K,V)或者reduce(K,list(V))，不灵活。而spark用的是RDD</strong><ul><li><strong>RDD是个逻辑概念，不占内存空间(除非缓存)</strong></li><li><strong>RDD中的数据是在内存里的，但是也只是在计算的时候，算完了就消失了，不会像list一样常驻内存</strong></li><li><strong>RDD包含不同分区，每个分区由不同task在不同节点处理</strong></li></ul></li></ul></li><li><strong>数据操作：transformation()和action()</strong><ul><li><strong>transformation()：对RDD作单向操作产生新的RDD，而不对原来RDD进行修改</strong><ul><li><strong>注：在Spark中RDD因为流水线执行和容错机制，所以RDD被设计成不可变类型</strong></li></ul></li><li><strong>action()：对数据结果进行后处理，产生输出结果，并触发spark提交job真正执行数据处理任务</strong></li></ul></li><li><strong>计算结果处理：</strong><ul><li><strong>不需要Driver端计算的就放到分布式文件系统中，需要计算就发到Driver端计算结果</strong><br><a name="fdRRn"></a></li></ul></li></ol><h2 id="如何生成逻辑处理流程："><a href="#如何生成逻辑处理流程：" class="headerlink" title="如何生成逻辑处理流程："></a>如何生成逻辑处理流程：</h2><ol><li><strong>由transformation()算子产生RDD</strong></li><li><strong>如何建立RDD之间的数据依赖关系？</strong><ul><li><strong>新生成的RDD分区个数：由用户指定或直接由父RDD分区个数最大值决定</strong></li><li><strong>RDD分区间的依赖关系：如下图所示，分为宽依赖和窄依赖</strong></li></ul></li></ol><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/0.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/Spark%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>窄依赖：新生成的RDD中的每个分区都依赖父RDD的一部分分区，可以根据子RDD依赖于父RDD的分区的全部数据进行判断，包括以下四种依赖</strong><ul><li><strong>一对一依赖：map()、fliter()</strong></li><li><strong>区域依赖：union()</strong></li><li><strong>多对一依赖：join()、cogroup()</strong></li><li><strong>多对多依赖：cartesian()</strong></li></ul></li><li><strong>宽依赖：新生成的RDD的分区依赖父RDD的每个分区的一部分，可以根据子RDD依赖于父RDD的分区的部分数据进行判断</strong><ul><li><strong>如图中RDD2只需要RDD1中id为1或2的数据，不需要全部读取</strong></li></ul></li></ul><ol start="3"><li><strong>如何计算RDD中的数据</strong><ul><li><strong>文中讲解了对输入数据进行map()和mapPartitions()的区别，P49</strong></li><li><strong>map()操作，相当于对每一个元素进行操作后就立即输出结果，来一个处理一个</strong></li><li><strong>mapPartitions()操作，相当于首先加载整个分区中的数据，然后一次性处理完后再输出结果</strong></li></ul></li></ol><p>​<br /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;uidqd&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;逻辑处理流程四部分：&quot;&gt;&lt;a href=&quot;#逻辑处理流程四部分：&quot; class=&quot;headerlink&quot; title=&quot;逻辑处理流程四部分：&quot;&gt;&lt;/a&gt;逻辑处理流程四部分：&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;str</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>jk式万能回溯法</title>
    <link href="https://mactql.github.io/posts/2484785620.html"/>
    <id>https://mactql.github.io/posts/2484785620.html</id>
    <published>2022-02-08T12:24:00.000Z</published>
    <updated>2022-02-08T12:51:09.862Z</updated>
    
    <content type="html"><![CDATA[<p><a name="pLjmt"></a></p><h2 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h2><ol><li><strong>画出解空间树型图</strong></li><li><strong>根据经验写出dfs需要的参数</strong></li><li><strong>写上结束条件</strong></li><li><strong>根据树型图写出for循环，并与图中每一层比较是否对应</strong></li><li><strong>接下来套回溯模版即可</strong></li><li><strong>若返回值需要存入数据结构且会被回溯清空，需要另外备份一份才能存入</strong></li></ol><p><a name="wq2o1"></a></p><h2 id="使用案例1：leetcode77-组合"><a href="#使用案例1：leetcode77-组合" class="headerlink" title="使用案例1：leetcode77 组合"></a>使用案例1：leetcode77 组合</h2><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/jk%E5%BC%8F%E4%B8%87%E8%83%BD%E5%9B%9E%E6%BA%AF%E6%B3%95/0.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/jk%E5%BC%8F%E4%B8%87%E8%83%BD%E5%9B%9E%E6%BA%AF%E6%B3%95/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><a name="jVpwE"></a></p><h3 id="配套使用方法："><a href="#配套使用方法：" class="headerlink" title="配套使用方法："></a>配套使用方法：</h3><ol><li><strong>假设n=4，k=3，则画出树型图如下：</strong></li></ol><p><img src="https://jktql.oss-cn-shanghai.aliyuncs.com/article/jk%E5%BC%8F%E4%B8%87%E8%83%BD%E5%9B%9E%E6%BA%AF%E6%B3%95/1.png" class="lazyload placeholder" data-srcset="https://jktql.oss-cn-shanghai.aliyuncs.com/article/jk%E5%BC%8F%E4%B8%87%E8%83%BD%E5%9B%9E%E6%BA%AF%E6%B3%95/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ol start="2"><li><strong>思考dfs需要的参数：n，k，当前到第几个数了index，当前的临时tempList</strong></li><li><strong>结束条件：index到n，说明已经找到一个解了</strong></li><li><strong>for循环：若index=0，则从1开始，否则从上一个存入的数+1开始，一直到k结束</strong><br><a name="sV3RT"></a><h3 id="代码答案："><a href="#代码答案：" class="headerlink" title="代码答案："></a>代码答案：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; ans = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; combine(<span class="keyword">int</span> n, <span class="keyword">int</span> k) &#123;</span><br><span class="line">    dfs(k,<span class="number">0</span>,<span class="keyword">new</span> LinkedList&lt;Integer&gt;(),n);</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> numOfList,<span class="keyword">int</span> curindex,List&lt;Integer&gt; temp,<span class="keyword">int</span> maxNum)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(curindex == numOfList)&#123;</span><br><span class="line">        ans.add(<span class="keyword">new</span> LinkedList&lt;Integer&gt;(temp));</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = (temp.isEmpty() ? <span class="number">1</span> :temp.get(curindex-<span class="number">1</span>)+<span class="number">1</span>);i &lt;= maxNum;i++)&#123;</span><br><span class="line">        temp.add(i);</span><br><span class="line">        dfs(numOfList,curindex+<span class="number">1</span>,temp,maxNum);</span><br><span class="line">        temp.remove(curindex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><br /><br />​<br />]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;pLjmt&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;步骤：&quot;&gt;&lt;a href=&quot;#步骤：&quot; class=&quot;headerlink&quot; title=&quot;步骤：&quot;&gt;&lt;/a&gt;步骤：&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;画出解空间树型图&lt;/strong&gt;&lt;/li&gt;
&lt;</summary>
      
    
    
    
    <category term="Leetcode刷题笔记" scheme="https://mactql.github.io/categories/Leetcode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Leetcode" scheme="https://mactql.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>概率论基本知识</title>
    <link href="https://mactql.github.io/posts/3471347229.html"/>
    <id>https://mactql.github.io/posts/3471347229.html</id>
    <published>2021-10-16T04:35:00.000Z</published>
    <updated>2021-10-18T06:25:29.777Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么叫联合概率？"><a href="#什么叫联合概率？" class="headerlink" title="什么叫联合概率？"></a>什么叫联合概率？</h2><p><strong>联合概率：P(AB)代表了A、B两个事件同时发生的概率大小</strong></p><h2 id="什么叫条件概率？"><a href="#什么叫条件概率？" class="headerlink" title="什么叫条件概率？"></a>什么叫条件概率？</h2><p><strong>条件概率：P(A|B)表示A在B发生的条件下的发生的概率，当P(B)&gt;0时，条件概率如下</strong><br><img src="/medias/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/0.png" class="lazyload placeholder" data-srcset="/medias/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><img src="/medias/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/1.png" class="lazyload placeholder" data-srcset="/medias/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么叫联合概率？&quot;&gt;&lt;a href=&quot;#什么叫联合概率？&quot; class=&quot;headerlink&quot; title=&quot;什么叫联合概率？&quot;&gt;&lt;/a&gt;什么叫联合概率？&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;联合概率：P(AB)代表了A、B两个事件同时发生的概率大小&lt;/strong&gt;</summary>
      
    
    
    
    <category term="硕士课题学习笔记" scheme="https://mactql.github.io/categories/%E7%A1%95%E5%A3%AB%E8%AF%BE%E9%A2%98%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="贝叶斯网络" scheme="https://mactql.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>《NAS-BERT：神经架构搜索与自适应BERT压缩》论文笔记</title>
    <link href="https://mactql.github.io/posts/2369829638.html"/>
    <id>https://mactql.github.io/posts/2369829638.html</id>
    <published>2021-10-15T12:09:00.000Z</published>
    <updated>2021-10-15T12:15:30.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><p><strong>题目：《NAS-BERT: Task-agnostic and Adaptive-size BERT Compression with Neural Architecture Search》</strong></p><hr><h2 id="理论方法阐释"><a href="#理论方法阐释" class="headerlink" title="理论方法阐释"></a>理论方法阐释</h2><p><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/0.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><strong>首先给定一个Teacher的模型，在论文中用的是BERT-base。把这个Teacher模型均匀的划分为四个Block，例如前三层作为一个Block，后面以此类推。对于每一个Blcok，我们建立一个NAS Search Block去学习/模仿对应Block的信息或者说学习能力</strong><br><strong>具体的做法是这样的，一个数据流进来，通过对数据流forward可以得到对应数据流的引表针，那么对每一个Block都可以得到他们的输入输出，每个Block的输入输出代表了他们的函数映射。为了模仿这个函数映射，我们就用这个映射去训练一个NAS Search Block来学习对应的Block的能力，NAS Search Block就是图(a)中所示的框架</strong><br><strong>NAS Search Block假设有六层，每一层有c个 candidate Operation，通过在每一层选择 candidate Operation构成一条自底向上的路径，可以看到可以有非常多的路径可以选择，通过训练得到一条性能最好的路径得到架构</strong><br><strong>candidate Operation有以下几种选择</strong></p><ul><li><strong>Multi-head Attention</strong></li><li><strong>Feed-forward Network</strong></li><li><strong>卷积</strong></li><li><strong>无Operation</strong></li></ul><hr><h2 id="实验方法阐释"><a href="#实验方法阐释" class="headerlink" title="实验方法阐释"></a>实验方法阐释</h2><ul><li><strong>在实验中使用的Teacher模型，是一个100M的标准的BERT base的模型，训练中也是使用标准的16GB的数据</strong></li><li><strong>模型使用的是12层的Transformer，hidden size 768</strong></li><li><strong>super-net用的是24层，为什么用24层呢，是因为一个Transformer里有两层，Multi-head Attention和Feed-forward Network</strong></li><li><strong>为了评估架构的模型效果，对架构进行重新训练。由于重训的代价比较高，论文中采用了5，10，30，60M四种模型的setting</strong><ul><li><strong>NAS-BERT-5, NAS-BERT-10, NAS-BERT-30, NAS-BERTE-60</strong></li><li><strong>在八个GLUE 的benchmark上以及SquAD1.0和SquAD2.0数据上做了性能的评测</strong></li></ul></li></ul><h2 id="实验1"><a href="#实验1" class="headerlink" title="实验1"></a>实验1</h2><p><strong>首先在5，10，30，60M四种模型尺寸的setting下和不同训练方式下对比NAS-BERT和BERT的效果</strong><br><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>PF和KD是在两种不同的训练方式去对比模型的效果</strong><ul><li><strong>PF表示pre-training和fine-training两个基本的范式</strong></li><li><strong>KD表示用压缩的方式做两阶段的知识蒸馏</strong></li></ul></li><li><strong>测试了模型的计算量(FLOPs)、加速比(Speedup)、八个数据集以及八个数据集的平均值</strong></li><li><strong>可以看到在不同的模型Setting下，NAS-BERT都显著超过BERT模型，并且当模型越小差异值越大</strong></li></ul><h2 id="实验2"><a href="#实验2" class="headerlink" title="实验2"></a>实验2</h2><p><strong>和之前的模型压缩的工作进行对比</strong><br><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><p><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>在八种数据集上以及SQuAD1.1和2.0数据集上分别在验证集和测试集上进行对比，还加入了数据增广的模型进行对比，如图中带*的模型</strong></li><li><strong>可以看到不管是在验证集还是测试集上，NAS-BERT都要显著超过之前的方法</strong></li></ul><h2 id="实验3"><a href="#实验3" class="headerlink" title="实验3"></a>实验3</h2><p><strong>测试如果提出的NAS-BERT不使用progressive shrinking的性能效果</strong><br><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><strong>在第4个epoch的时候加入progressive shrinking，即图中红线所示。蓝线是不加入progressive shrinking</strong><br><strong>可以看到，加入progressive shrinking以后，loss是快速下降的，也就证明super-net的收敛速度是显著加快的</strong><br><strong>从表格上也可以看出，使用了progressive shrinking是显著超过不使用progressive shrinking的</strong></p><h2 id="实验4"><a href="#实验4" class="headerlink" title="实验4"></a>实验4</h2><p><strong>测试不同的shrinking方法的性能效果</strong><br><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/5.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/5.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h2 id="实验5"><a href="#实验5" class="headerlink" title="实验5"></a>实验5</h2><p><strong>对比测试在不同的蒸馏setting下的NAS-BERT和BERT的性能效果</strong><br><img src="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/6.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8ANAS-BERT%EF%BC%9A%E7%A5%9E%E7%BB%8F%E6%9E%B6%E6%9E%84%E6%90%9C%E7%B4%A2%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94BERT%E5%8E%8B%E7%BC%A9%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><strong>实验分别测试了仅上游使用蒸馏、仅下游使用蒸馏的以及上下游同时使用蒸馏</strong><br><strong>在八个数据集上NAS-BERT都显著超过BERT模型，证明了NAS-BERT模型并不是只有在两阶段蒸馏的情况下才有效</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;题目：《NAS-BERT: Task-agnostic and Adaptive-size BERT Com</summary>
      
    
    
    
    <category term="硕士每周论文笔记" scheme="https://mactql.github.io/categories/%E7%A1%95%E5%A3%AB%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Transformer" scheme="https://mactql.github.io/tags/Transformer/"/>
    
  </entry>
  
  <entry>
    <title>Spark job中的stage划分与三种提交模式</title>
    <link href="https://mactql.github.io/posts/2922386947.html"/>
    <id>https://mactql.github.io/posts/2922386947.html</id>
    <published>2021-09-30T07:54:00.000Z</published>
    <updated>2021-09-30T08:00:55.211Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先要了解宽依赖和窄依赖是什么？"><a href="#首先要了解宽依赖和窄依赖是什么？" class="headerlink" title="首先要了解宽依赖和窄依赖是什么？"></a>首先要了解宽依赖和窄依赖是什么？</h2><ul><li><strong>窄依赖：每个RDD对应一个父RDD，每个父子RDD是一对一的关系</strong></li><li><strong>宽依赖：父RDD的partition被多个子RDD使用，父子RDD是错综复杂的关系</strong><ul><li><strong>产生了shuffle操作就是宽依赖</strong></li></ul></li></ul><hr><h2 id="什么是stage？"><a href="#什么是stage？" class="headerlink" title="什么是stage？"></a>什么是stage？</h2><p><strong>通过之前的学习，我们了解到Spark job是由action算子触发的，每个action算子触发一个job</strong><br><strong>每个job会被划分成多个stage，每个stage是由一组并行的Task来完成的</strong></p><h3 id="那么Stage是怎么划分的呢？"><a href="#那么Stage是怎么划分的呢？" class="headerlink" title="那么Stage是怎么划分的呢？"></a>那么Stage是怎么划分的呢？</h3><ul><li><strong>stage的划分依据就是看是否产生了shuffle，即是否是宽依赖</strong></li><li><strong>遇到一个shuffle(宽依赖)，就会被划分成前后两个stage，如下图所示</strong></li></ul><p><img src="/medias/Sparkjob%E4%B8%AD%E7%9A%84stage%E5%88%92%E5%88%86%E4%B8%8E%E4%B8%89%E7%A7%8D%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F/0.png" class="lazyload placeholder" data-srcset="/medias/Sparkjob%E4%B8%AD%E7%9A%84stage%E5%88%92%E5%88%86%E4%B8%8E%E4%B8%89%E7%A7%8D%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><hr><h2 id="下面我们学习一下Spark-job提交的三种模式"><a href="#下面我们学习一下Spark-job提交的三种模式" class="headerlink" title="下面我们学习一下Spark job提交的三种模式"></a>下面我们学习一下Spark job提交的三种模式</h2><ul><li><strong>第一种：Standalone模式</strong></li></ul><p><strong><code>spark-submit --master spark://bigdata01:7077</code></strong></p><ul><li><strong>第二种：Yarn client模式（主要用于测试）</strong></li></ul><p><strong><code>spark-submit --master yarn --deploy-mode client</code></strong></p><ul><li><strong>第三种：Yarn cluster模式（推荐）</strong></li></ul><p><strong><code>spark-submit --master yarn --deploy-mode cluster</code></strong></p><h3 id="三种模式的架构如下图所示"><a href="#三种模式的架构如下图所示" class="headerlink" title="三种模式的架构如下图所示"></a>三种模式的架构如下图所示</h3><p><img src="/medias/Sparkjob%E4%B8%AD%E7%9A%84stage%E5%88%92%E5%88%86%E4%B8%8E%E4%B8%89%E7%A7%8D%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F/1.png" class="lazyload placeholder" data-srcset="/medias/Sparkjob%E4%B8%AD%E7%9A%84stage%E5%88%92%E5%88%86%E4%B8%8E%E4%B8%89%E7%A7%8D%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;首先要了解宽依赖和窄依赖是什么？&quot;&gt;&lt;a href=&quot;#首先要了解宽依赖和窄依赖是什么？&quot; class=&quot;headerlink&quot; title=&quot;首先要了解宽依赖和窄依赖是什么？&quot;&gt;&lt;/a&gt;首先要了解宽依赖和窄依赖是什么？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;</summary>
      
    
    
    
    <category term="《Spark性能优化的道与术》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8ASpark%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E9%81%93%E4%B8%8E%E6%9C%AF%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>《分布式进化算法及其模型：最新进展综述》论文笔记</title>
    <link href="https://mactql.github.io/posts/824286531.html"/>
    <id>https://mactql.github.io/posts/824286531.html</id>
    <published>2021-09-30T02:31:00.000Z</published>
    <updated>2021-09-30T02:35:00.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><ul><li><strong>题目：Distributed evolutionary algorithms and their models: A survey of the state-of-the-art</strong></li><li><strong>作者：Gong Y-J, Chen W-N, Zhan Z-H</strong></li><li><strong>期刊：Applied Soft Computing</strong></li><li><strong>时间：2015.09</strong></li><li><strong>链接：</strong><a href="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/0.png">Distributed evolutionary algorithms and their models: A survey of the state-of-the-art - ScienceDirect</a></li><li><strong>关键字：分布式进化计算；协同进化计算；进化算法；全局优化；多目标优化</strong></li></ul><hr><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li><strong>本文对最先进的分布式进化算法和模型进行了综述</strong><ul><li><strong>人口分布模型具有主从、岛、蜂窝、分层和池架构，可在人口、个体或操作级别并行化进化任务</strong></li><li><strong>维数分布模型包括协同进化和多智能体模型，它们侧重于降维</strong></li><li><strong>洞察模型，例如同步、同质性、通信、拓扑、加速、还介绍和讨论了优点和缺点</strong></li></ul></li><li><strong>还重点介绍了该领域的最新热点，包括基于云和 MapReduce 的实现、基于 GPU 和 CUDA 的实现、分布式进化多目标优化和实际应用</strong></li><li><strong>还讨论了许多未来的研究方向</strong></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><ul><li><strong>分布式进化算法框架如下图所示：</strong><ul><li><strong>基本进化算法包括：遗传算法GA，进化规划EP，进化策略ES，遗传规划GP和差分进化DE。此外蚁群算法ACO和粒子群优化PSO与进化算法具有相同特征，故也包含在内</strong></li><li><strong>分布式进化模型用来并行化处理算法，包括：常用主从/岛屿/细胞模型，另外层次/池/协同进化/多代理模型也被广泛接受</strong></li><li><strong>设计好模型后，采用不同的编程环境，包括Java、MPI、MapReduce等</strong></li><li><strong>最后用于部署的物理平台，包括集群、网格、P2P网络、云和GPU</strong></li></ul></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><hr><h3 id="下面介绍分布式进化模型"><a href="#下面介绍分布式进化模型" class="headerlink" title="下面介绍分布式进化模型"></a>下面介绍分布式进化模型</h3><h4 id="主从模型："><a href="#主从模型：" class="headerlink" title="主从模型："></a>主从模型：</h4><ul><li><strong>主节点进行交叉/变异/选择，把个体发给从节点进行适应度评估，从节点评估好再发送给主节点,如下图所示</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>缺点：当适应度评估时间小于主从通信时间时，因为主从通信时间导致效率低下。</strong></li><li><strong>为了解决这个缺点，有两种主从模型的变体：</strong><ul><li><strong>从节点不仅评估适应度，还有更新任务</strong></li><li><strong>每个从节点包含一个子群，主节点从从节点接收最佳个体并把全局最佳信息发送给所有从节点</strong></li></ul></li><li><strong>总结：当适应度评估时间远大于主从通信时间时，使用主从模型效果很好</strong></li></ul><h4 id="岛屿模型："><a href="#岛屿模型：" class="headerlink" title="岛屿模型："></a>岛屿模型：</h4><ul><li><strong>把种群分成多个子种群，每个子种群对应一个处理器，个体会按照设定的时间间隔迁移到另一个岛</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>岛屿模型节省时间，提高EA的全局搜索能力，不同岛屿中的个体可以向不同方向进化，保证种群多样性</strong></li><li><strong>缺点：通信频率低时，算法收敛速度很慢，并且迁移范围对算法性能影响很大</strong></li></ul><h4 id="细胞模型："><a href="#细胞模型：" class="headerlink" title="细胞模型："></a>细胞模型：</h4><ul><li><strong>每个个体排列在网格上，只能与相邻的个体竞争和交配</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>可以采用并行计算来评估每个染色体的适应度，并且在局部进行交叉/变异/选择到相邻的邻居</strong></li><li><strong>优点：显著提高对所有染色体的评估速度</strong></li><li><strong>缺点：需要一个大规模的集群来处理</strong></li></ul><h4 id="混合模型："><a href="#混合模型：" class="headerlink" title="混合模型："></a>混合模型：</h4><ul><li><strong>多种分布式模型组合，例如岛屿+主从模型等</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/5.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/5.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>岛主从模型：</strong><ul><li><strong>种群划分成多个子种群，在不同的节点定期进行迁移通信</strong></li><li><strong>对于每个子群，每个主节点会把单独的评估任务发送到从节点</strong></li><li><strong>优点：减少了主从模型中单个主节点的依赖性</strong></li></ul></li><li><strong>岛细胞模型：</strong><ul><li><strong>如图所示，提高了扩展性和容错性</strong></li></ul></li><li><strong>岛岛模型：</strong><ul><li><strong>实现两种迁移方式：可在本地迁移和全局迁移</strong></li><li><strong>优点：提高了每个节点的效率</strong></li></ul></li></ul><h4 id="泳池模型："><a href="#泳池模型：" class="headerlink" title="泳池模型："></a>泳池模型：</h4><ul><li><strong>泳池是一个长度为n的全局共享数组，表示种群中n个个体。然后根据节点个数划分泳池成多个段，每个段对应一个节点。每个节点可以读取任意段中的个体，但是只能往自己段里写。</strong></li><li><strong>优化过程中，节点可以随机选不同段中的个体进行操作，如果生成的后代比自己段中的适应度更好就写回自己的段中</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/6.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/6.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>难点在于如何实现一个资源池，如数据库系统，MapReduce等</strong></li></ul><h4 id="协同进化模型："><a href="#协同进化模型：" class="headerlink" title="协同进化模型："></a>协同进化模型：</h4><ul><li><strong>根据节点数量划分每个节点上的向量，确定主变量，其余为从变量</strong></li><li><strong>在主变量上进行进化操作，从变量不变。评估时计算整个向量的适应度。通信阶段，更新其次变量</strong></li></ul><p><img src="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/7.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%A8%A1%E5%9E%8B%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E7%BB%BC%E8%BF%B0%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/7.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><h4 id="多代理模型："><a href="#多代理模型：" class="headerlink" title="多代理模型："></a>多代理模型：</h4><ul><li><strong>把分布式进化模型视为n个玩家玩策略游戏的系统，每个玩家有一个收益函数，该函数取决于自己和有限邻居的行为，每个玩家都会选择最大收益的行为</strong></li></ul><hr><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>本文是一篇综述，对每个分布式进化模型及其特点都做了简要概述和点评</strong></p><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><strong>[29] B. Dorronsoro, G. Danoy, A J. Nebro, P. Bouvry, Achieving super-linear per formance in parallel multi-objective evolutionary algorithms by means of cooperative coevolution, Comput. Oper Res. 40(6)(2013)1552-1563</strong><br><strong>[44] M. Garcia-arenas, J-J. Merelo, A M. Mora, P. Castillo, G. Romero, J. L, ]. Laredo. Assessing speed-ups in commodity cloud storage services for distributed evo lutionary algorithms, in: IEEE Congress on Evolutionary Computation(CEC), 2011,pp.304-3</strong><br><strong>[65] F.M.Johar, F.A. Azmin, M K. Suaidi, A.S. Shibghatullah, B H Ahmad, S.N.Salleh,M.Z. AA. Aziz, M. Md Shukor, A review of genetic algorithms and parallel genetic algorithms on graphics processing unit(GPU), in: 2013 IEEE Interna tional Conference on Control System, Computing and Engineering (CCSCE) 2013,pp.264-269</strong><br><strong>[72] X. Li, X Yao, Cooperatively coevolving particle swarms for large scale opti mization, IEEE Trans. Evol. Comput. 16(2)(2012)210-224</strong><br><strong>[97] M. Pedemonte, S. Nesmachnow, H. Cancela, A survey on parallel ant colony optimization, Appl. Soft Comput. 11(8)(2011)5181-5197</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;题目：Distributed evolutionary algorithms and their</summary>
      
    
    
    
    <category term="硕士每周论文笔记" scheme="https://mactql.github.io/categories/%E7%A1%95%E5%A3%AB%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="遗传算法" scheme="https://mactql.github.io/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式" scheme="https://mactql.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>剖析HDFS/MR小文件与数据倾斜问题</title>
    <link href="https://mactql.github.io/posts/2599323417.html"/>
    <id>https://mactql.github.io/posts/2599323417.html</id>
    <published>2021-09-24T04:56:00.000Z</published>
    <updated>2021-09-24T04:58:41.450Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是小文件问题？"><a href="#什么是小文件问题？" class="headerlink" title="什么是小文件问题？"></a>什么是小文件问题？</h2><ul><li><strong>HDFS上如果小文件很多，每个小文件都会在NameNode中占用150字节的内存空间</strong></li><li><strong>而在MR中每个小文件都会占一个block，每个block都会产生数据分片对应一个Map任务，导致Map任务特别多，消耗了很多启动Map任务的性能</strong></li></ul><h2 id="如何解决小文件问题？"><a href="#如何解决小文件问题？" class="headerlink" title="如何解决小文件问题？"></a>如何解决小文件问题？</h2><p><strong>HDFS提供了两种容器，SequenceFile 和 MapFile</strong></p><ul><li><strong>SequenceFile</strong><ul><li><strong>是一种二进制文件，会直接把&lt;key,Value&gt;的形式序列化到文件中</strong></li><li><strong>所以，我们可以把小文件进行合并成键值对，Key为文件名，文件内容作为Value，这样序列化组成一个大文件</strong></li><li><strong>缺点：合并后不容易查看，需要通过遍历才能看每个小文件</strong></li></ul></li><li><strong>MapFile</strong><ul><li><strong>是排序后的SequenceFile</strong></li><li><strong>MapFile有两部分，分别是index和data。其中index记录key，以及data在文件中的偏移量。</strong></li><li><strong>优点：查询文件时，可以通过index快速找到数据位置</strong></li></ul></li></ul><hr><h2 id="什么叫数据倾斜问题？"><a href="#什么叫数据倾斜问题？" class="headerlink" title="什么叫数据倾斜问题？"></a>什么叫数据倾斜问题？</h2><ul><li><strong>比如文件里有1000w条数据，里面都是1和0，但是1的数据有900w条，0的数据只有100w条，所以1就是数据倾斜了，这样造成的结果就是处理1的Reduce任务很慢很慢，处理0的Reduce任务早就好了</strong></li><li><strong>总结：MR任务执行时，大部分Reduce节点都处理完毕，但有一个或几个Reduce任务很慢很慢，导致整个Reduce任务很慢</strong></li></ul><h2 id="怎么解决数据倾斜问题？"><a href="#怎么解决数据倾斜问题？" class="headerlink" title="怎么解决数据倾斜问题？"></a>怎么解决数据倾斜问题？</h2><p><strong>有两种解决方案：</strong></p><ul><li><strong>增加Reduce任务个数：治标不治本</strong></li><li><strong>把倾斜的数据打散：比如1倾斜，可以把1改成1_0、1_1等，分到多个Reduce中即可</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是小文件问题？&quot;&gt;&lt;a href=&quot;#什么是小文件问题？&quot; class=&quot;headerlink&quot; title=&quot;什么是小文件问题？&quot;&gt;&lt;/a&gt;什么是小文件问题？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HDFS上如果小文件很多，每个小文件都会在NameNod</summary>
      
    
    
    
    <category term="《拿来就用的企业级解决方案》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8A%E6%8B%BF%E6%9D%A5%E5%B0%B1%E7%94%A8%E7%9A%84%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MapReduce" scheme="https://mactql.github.io/tags/MapReduce/"/>
    
    <category term="HDFS" scheme="https://mactql.github.io/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>《Hadoop和Spark上遗传算法分布式架构》论文笔记</title>
    <link href="https://mactql.github.io/posts/2233902538.html"/>
    <id>https://mactql.github.io/posts/2233902538.html</id>
    <published>2021-09-21T08:24:00.000Z</published>
    <updated>2021-09-27T02:44:42.784Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><ul><li><strong>题目：Parallel and distributed architecture of genetic algorithm on Apache Hadoop and Spark</strong></li><li><strong>作者：Hao-chun Lu，F.J.Hwang，Yao-Huei Huang</strong></li><li><strong>期刊：Applied Soft Computing Journal 95(2020) 106497</strong></li><li><strong>时间：2020.06</strong></li><li><strong>链接：</strong>[<a href="https://webvpn1.jiangnan.edu.cn/https/77726476706e69737468656265737421e7e056d234336155700b8ca891472636a6d29e640e/science/article/pii/S1568494620304361]">https://webvpn1.jiangnan.edu.cn/https/77726476706e69737468656265737421e7e056d234336155700b8ca891472636a6d29e640e/science/article/pii/S1568494620304361]</a></li><li><strong>关键字：遗传算法；并行与分布式计算；Apache Hadoop；Apache Spark</strong></li></ul><hr><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li><strong>如果遗传算子所需的迭代过程可以在并行分布式计算体系结构中实现，那么遗传算法在解决大规模优化问题方面的效率将得到提高</strong></li><li><strong>开发的计算框架以将 GA核心操作符 分配到 Apache Hadoop 中的复杂机制为特点，与云计算模型相匹配</strong></li><li><strong>所提出的体系结构可以很容易地扩展到 Apache Spark</strong></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><ul><li><strong>文章提出GAN分布式计算体系结构的并行化，是一种基于Apache的遗传算法并行分布式体系结构</strong><ul><li><strong>通过使用相对高效的并行化机制调度遗传算法的核心操作符，提高了HDFS的利用率，减少HDFS作业处理的空闲时间，并且这个并行化机制可以扩展到Apache Spark上的RDD</strong></li></ul></li></ul><hr><h3 id="前人设计的架构"><a href="#前人设计的架构" class="headerlink" title="前人设计的架构"></a>前人设计的架构</h3><ul><li><strong>Verma设计的并行架构：</strong></li></ul><p><img src="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/0.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>Mapper用来评估适应度，Reducer用来选择/交叉/变异</strong></li><li><strong>缺点：</strong><ul><li><strong>Reducer中进化不考虑全种群，种群多样性不足会过早收敛</strong></li><li><strong>Mapper中评估适应度后把染色体分区后传给多个Reducer，每个Reducer上的染色体GA轮盘赌概率会变化，导致选择结果不准确，如下图所示</strong></li></ul></li></ul><p><img src="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>​Kečo 和 Subasi设计的并行架构：</strong></li></ul><p><img src="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>第一次迭代，在Mapper中首先评估初始染色体的适应度，然后交叉/变异后再评估一次，然后进行选择</strong></li><li><strong>第二次迭代开始，每次迭代不执行E0，在交叉/变异后评估适应度并判断评估结果。如果满足条件直接输出，不满足则继续迭代</strong></li><li><strong>缺点：</strong><ul><li><strong>没有并行处理GA算子</strong></li></ul></li></ul><hr><h3 id="本文提出的架构"><a href="#本文提出的架构" class="headerlink" title="本文提出的架构"></a>本文提出的架构</h3><p><img src="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>步骤如下：</strong><ol><li><strong>首先生成初始种群，转换成子种群并激活MapReduce1</strong></li><li><strong>在MapReduce1中把每个子种群分配给多个Mapper进行评估适应度</strong></li><li><strong>激活MapReduce2，准备多个交叉池（从整个子种群中选择，组成多个交叉池，防止过早收敛）</strong></li><li><strong>迭代过程：</strong><ol><li><strong>每个Mapper和Reducer对应，依次执行交叉、变异、评估，如上图所示，将结果返回到主程序</strong></li><li><strong>主程序对所有从Reducer收集到的染色体执行选择算子</strong></li><li><strong>判断停止条件，不满足则继续迭代</strong></li></ol></li></ol></li><li><strong>优点：</strong><ul><li><strong>选择算子在主程序中</strong></li><li><strong>交叉/变异同时并行执行，产生的任何染色体都直接在Reducer中评估</strong></li></ul></li></ul><h3 id="将Hadoop并行架构用到Spark上"><a href="#将Hadoop并行架构用到Spark上" class="headerlink" title="将Hadoop并行架构用到Spark上"></a>将Hadoop并行架构用到Spark上</h3><p><img src="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" class="lazyload placeholder" data-srcset="/medias/%E3%80%8AHadoop%E5%92%8CSpark%E4%B8%8A%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E3%80%8B%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>原理同Hadoop</strong></li></ul><hr><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol><li><strong>评估算子不需要其他染色体信息，独立工作，可以并行化</strong></li><li><strong>交叉算子需要在当前整个种群中选出两条染色体，不然会过早收敛。并且需要设计额外程序保证交叉后的染色体是可行解</strong></li><li><strong>变异算子调整交叉后的染色体保持多样性，也需要额外程序保证变异后是可行解</strong></li><li><strong>选择算子不能在多个子种群中进行选择，有必要把多个Reducer评估后的染色体收集起来形成一个新种群再选择，否则会导致出现Verma架构的缺点</strong></li></ol><ul><li><strong>设计的并行GA架构要满足上述四条</strong></li></ul><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><strong>[19] K. Gallagher, M. Sambridge, Genetic algorithms: a powerful tool for largescale nonlinear optimization problems, Comput. Geosci. 20 (7) (1994) 1229–1236.</strong><br><strong>[22] G. Luque, E. Alba, Parallel models for genetic algorithms, in: Parallel Genetic Algorithms: Theory and Real World Applications, Vol. 367, 2011.</strong><br><strong>[24] L.D. Geronimo, F. Ferrucci, A. Murolo, V. Sarro, A parallel genetic algorithm based on Hadoop MapReduce for the automatic generation of JUnit test suites, in: The IEEE 5th International Conference on Software Testing, Verification and Validation, 2012, pp. 785–793.</strong><br><strong>[26] W. Yu, W. Zhang, Study on function optimization based on master–slave structure genetic algorithm. in: The 8th International Conference on Signal Processing, 2006, pp. 3.</strong><br><strong>[27] N. Melab, E.G. Talbi, GPU-based island model for evolutionary algorithms, in: Proceedings of the 12 Annual Conference on Genetic and Evolutionary Computation, 2010, pp. 1089–1096.</strong><br><strong>[29] S. Arora, I. Chana, A survey of clustering techniques for big data analysis, in: The 5th International Conference - The Next Generation Information Technology Summit Confluence, 2014, pp. 59–65.</strong><br><strong>[30] D. Camacho, Bio-inspired clustering: basic features and future trends in the era of big data, in: 2015 IEEE 2nd International Conference on Cybernetics, CYBCONF, pp. 1–6.</strong><br><strong>[31] Y.J. Gong, W.N. Chen, Z.H. Zhan, J. Zhang, Y. Li, Q. Zhang, J.J. Li, Distributed evolutionary algorithm and their models: A survey of state-of-the-art, Appl. Soft Comput. 34 (2015) 286–300.</strong><br><strong>[33] J. Dean, S. Ghemawat, MapReduce: Simplified data processing on large clusters, Commun. ACM 51 (1) (2008) 107–113.</strong><br><strong>[37] A. Verma, X. Llorà, D.E. Goldberg, R.H. Campbell, Scaling genetic algorithms using MapReduce, in: The 9th IEEE International Conference Intelligent Systems Design and Applications, ISDA’09, 2009, pp. 13–18.</strong><br><strong>[38] D. Kečo, A. Subasi, Parallelization of genetic algorithms using Hadoop Map/Reduce, SouthEast Eur. J. Soft Comput. 1 (2) (2012).</strong><br><strong>[39] R.Z. Qi, Z.J. Wang, S.Y. Li, A parallel genetic algorithm based on spark for pairwise test suite generation, J. Comput. Sci. Tech. 31 (2) (2016) 417–427.</strong><br><strong>[42] R. Gu, X. Yang, J. Yan, Y. Sun, B. Wang, C. Yuan, Y. Huang, SHadoop: improving mapreduce performance by optimizing job execution mechanism in Hadoop clusters, J. Parallel Distrib. Comput. 74 (3) (2014) 2166–2179.</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本信息&quot;&gt;&lt;a href=&quot;#基本信息&quot; class=&quot;headerlink&quot; title=&quot;基本信息&quot;&gt;&lt;/a&gt;基本信息&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;题目：Parallel and distributed architecture of gene</summary>
      
    
    
    
    <category term="硕士每周论文笔记" scheme="https://mactql.github.io/categories/%E7%A1%95%E5%A3%AB%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
    <category term="遗传算法" scheme="https://mactql.github.io/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/"/>
    
    <category term="MapReduce" scheme="https://mactql.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据类型</title>
    <link href="https://mactql.github.io/posts/950473165.html"/>
    <id>https://mactql.github.io/posts/950473165.html</id>
    <published>2021-09-17T02:48:00.000Z</published>
    <updated>2021-09-17T02:50:02.058Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis常见数据类型"><a href="#Redis常见数据类型" class="headerlink" title="Redis常见数据类型"></a>Redis常见数据类型</h2><p><strong>上一章我们了解了Redis常见的五种数据类型，string、set、hash、sortedset、list，这里我们详细介绍一下</strong></p><hr><h3 id="首先是string"><a href="#首先是string" class="headerlink" title="首先是string"></a>首先是string</h3><p><strong>string可以存任何形式的内容，甚至是二进制数据或图片</strong><br><img src="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/0.png" class="lazyload placeholder" data-srcset="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><strong>在这些操作的基础上还有一次添加多个：mset 和一次查多个： mget</strong></p><hr><h3 id="hash类型"><a href="#hash类型" class="headerlink" title="hash类型"></a>hash类型</h3><p><strong>hash类型存的是字段和字段值的映射，类似是在存键值对，只能是字符串，常用来存对象</strong><br><img src="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/1.png" class="lazyload placeholder" data-srcset="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><strong>这里的有三个属性，key、field、name，其中field和name是key的value，而field是字段value是字段值，相当于是把一个键值对存在redis中，key是这个键值对的key</strong></p><hr><h2 id="list类型"><a href="#list类型" class="headerlink" title="list类型"></a>list类型</h2><p><strong>list是一个有序的字符串列表，而且是双向链表，常用来当作队列使用</strong><br><img src="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/2.png" class="lazyload placeholder" data-srcset="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><hr><h2 id="set类型"><a href="#set类型" class="headerlink" title="set类型"></a>set类型</h2><p><strong>set集合中的元素都是不重复且无序的</strong><br><img src="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/3.png" class="lazyload placeholder" data-srcset="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><hr><h2 id="sortedset类型"><a href="#sortedset类型" class="headerlink" title="sortedset类型"></a>sortedset类型</h2><p><strong>与set不同的是有序集合，相当于为每个元素指定一个分数，常用于获取topN的场景</strong><br><img src="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/4.png" class="lazyload placeholder" data-srcset="/medias/Redis%E6%A0%B8%E5%BF%83%E5%AE%9E%E8%B7%B5/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><br><strong>注意用zadd添加元素要<code>zadd key score value</code> 这样写，一定要在value前给他一个分数</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Redis常见数据类型&quot;&gt;&lt;a href=&quot;#Redis常见数据类型&quot; class=&quot;headerlink&quot; title=&quot;Redis常见数据类型&quot;&gt;&lt;/a&gt;Redis常见数据类型&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;上一章我们了解了Redis常见的五种数据类型，str</summary>
      
    
    
    
    <category term="《快速上手内存数据库Redis》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8A%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Redis" scheme="https://mactql.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>快速了解Redis</title>
    <link href="https://mactql.github.io/posts/4199058362.html"/>
    <id>https://mactql.github.io/posts/4199058362.html</id>
    <published>2021-09-17T02:00:00.000Z</published>
    <updated>2021-09-17T02:02:45.182Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是Redis？"><a href="#什么是Redis？" class="headerlink" title="什么是Redis？"></a>什么是Redis？</h2><ul><li><strong>Redis是一个高性能的基于内存的Key-Value数据库</strong></li><li><strong>可以在N多条记录中根据条件非常快的查找一条或几条记录</strong></li></ul><hr><h2 id="Redis的数据格式是什么样的？"><a href="#Redis的数据格式是什么样的？" class="headerlink" title="Redis的数据格式是什么样的？"></a>Redis的数据格式是什么样的？</h2><ul><li><strong>Redis数据格式为Key-Value</strong><ul><li><strong>Key：String</strong></li><li><strong>Value：String、Hash、List、Set、SortedSet……</strong></li></ul></li></ul><hr><h2 id="Redis应用场景有哪些？"><a href="#Redis应用场景有哪些？" class="headerlink" title="Redis应用场景有哪些？"></a>Redis应用场景有哪些？</h2><ul><li><strong>最常用来当作缓存系统：当用户需要向数据库取数据时，先看redis有没有，没有就去数据库里拿到redis中再从redis中取数据</strong></li><li><strong>计数器：新浪微博的评论数、点赞数</strong></li><li><strong>消息队列：不过用Kafka比较多了</strong></li></ul><hr><h2 id="Redis基础命令有哪些？"><a href="#Redis基础命令有哪些？" class="headerlink" title="Redis基础命令有哪些？"></a>Redis基础命令有哪些？</h2><p><img src="/medias/%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3Redis/0.png" class="lazyload placeholder" data-srcset="/medias/%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3Redis/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//添加一个键值对</span></span><br><span class="line">set【key】【value】 <span class="comment">//例如set a 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//获取指定key的value</span></span><br><span class="line"><span class="type">Keys</span>【key】<span class="comment">//例如Keys a</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//删除指定键值对</span></span><br><span class="line">del【key】<span class="comment">//例如del a</span></span><br></pre></td></tr></table></figure><hr><h2 id="Redis多数据库特性"><a href="#Redis多数据库特性" class="headerlink" title="Redis多数据库特性"></a>Redis多数据库特性</h2><p><strong>Redis有16个数据库【0-15】，默认在0号数据库，可以用select n 来指定数据库</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是Redis？&quot;&gt;&lt;a href=&quot;#什么是Redis？&quot; class=&quot;headerlink&quot; title=&quot;什么是Redis？&quot;&gt;&lt;/a&gt;什么是Redis？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Redis是一个高性能的基于内存的Key-Value数据</summary>
      
    
    
    
    <category term="《快速上手内存数据库Redis》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8A%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93Redis%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Redis" scheme="https://mactql.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>共享变量与Cache</title>
    <link href="https://mactql.github.io/posts/4244340064.html"/>
    <id>https://mactql.github.io/posts/4244340064.html</id>
    <published>2021-09-09T13:29:00.000Z</published>
    <updated>2021-09-09T13:50:01.760Z</updated>
    
    <content type="html"><![CDATA[<p><strong>默认情況下，一个算子函数中使用到了某个外部的变量，那么这个变量的值会被拷贝到每个task中，此时每个task只能操作自己的那份变量数据</strong><br><strong>Spark提供了两种共享变量，一种是 Broadcast Variable(广播变量)，另一种是 Accumulator(累加变量)</strong></p><hr><h2 id="Broadcast-Variable（广播变量）"><a href="#Broadcast-Variable（广播变量）" class="headerlink" title="Broadcast Variable（广播变量）"></a>Broadcast Variable（广播变量）</h2><blockquote><p><strong>Broadcast Variable（广播变量）会把指定的变量拷贝一份到每个节点上</strong></p><ul><li><strong>通过调用 SparkContext.broadcast(指定变量) 方法为指定的变量创建 只读 的广播变量，通过 广播变量.value() 方法获取值</strong></li><li><strong>优点：</strong><ul><li><strong>如下图所示，如果不使用广播变量，当map计算时会把外部变量拷贝到每个task中，当一个节点task很多的时候会消耗很多资源。用广播变量的话，每个节点只拷贝一份，大大提高了性能</strong></li></ul></li></ul></blockquote><p><img src="/medias/%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E4%B8%8ECache/0.png" class="lazyload placeholder" data-srcset="/medias/%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E4%B8%8ECache/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><hr><h2 id="Accumulator（累加器）"><a href="#Accumulator（累加器）" class="headerlink" title="Accumulator（累加器）"></a>Accumulator（累加器）</h2><p><strong>Accumulator 只能 专用于累加，并且除了Drive进程以外，其他进程都不能读取值</strong><br><strong>直接看案例就懂了</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="type">SparkSession</span>.builder().getOrCreate().sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment">//直接用外部变量获取RDD中元素的和</span></span><br><span class="line"><span class="keyword">var</span> sum = <span class="number">0</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).foreach( sum += _)</span><br><span class="line">println(sum)</span><br><span class="line">打印结果: <span class="number">0</span></span><br><span class="line">原因是外部变量是在<span class="type">Drive</span>进程中的，用foreach算子计算的和是局部变量传不到<span class="type">Drive</span>，在<span class="type">Drive</span>中println是打印不出来的</span><br><span class="line"></span><br><span class="line"><span class="comment">//用Accumulator获取RDD中元素的和</span></span><br><span class="line"><span class="keyword">var</span> sum = sc.longAccumulator</span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)).foreach(sum.add(_))</span><br><span class="line">println(sum.value)</span><br><span class="line">打印结果：<span class="number">10</span></span><br><span class="line">在<span class="type">Drive</span>进程中可以调用<span class="type">Accumulator</span>变量.value得到累加结果</span><br></pre></td></tr></table></figure><hr><h2 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h2><p><img src="/medias/%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E4%B8%8ECache/1.png" class="lazyload placeholder" data-srcset="/medias/%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E4%B8%8ECache/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>在未引入Cache时：</strong><ul><li><strong>如图所示，因transformation算子有lazy特性，在action之前不会执行。所以当计算result1时，会走一遍step1-&gt;2-&gt;3，当计算result2时，还会走一遍step1-&gt;2-&gt;3，极大浪费资源。</strong></li></ul></li><li><strong>那么现在引入Cache：</strong><ul><li><strong>在RDD2添加Cache后，计算result2时可以直接从Cache中取出计算过的RDD2即可，无需重复计算RDD2</strong></li></ul></li></ul><p><strong>由此可见，在需要重复调用的RDD上非常有必要添加Cache，直接使用<code>RDDname.cache()</code>即可</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;默认情況下，一个算子函数中使用到了某个外部的变量，那么这个变量的值会被拷贝到每个task中，此时每个task只能操作自己的那份变量数据&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;Spark提供了两种共享变量，一种是 Broadcast Variable(广播变</summary>
      
    
    
    
    <category term="《Spark快速上手》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8ASpark%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>RDD开发实战</title>
    <link href="https://mactql.github.io/posts/1890251266.html"/>
    <id>https://mactql.github.io/posts/1890251266.html</id>
    <published>2021-09-09T01:43:00.000Z</published>
    <updated>2021-09-09T13:34:23.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何创建RDD？"><a href="#如何创建RDD？" class="headerlink" title="如何创建RDD？"></a>如何创建RDD？</h2><ul><li><p><strong>创建RDD有三种方式</strong></p><ul><li><p><strong>基于集合创建RDD：使用sparkContext的parallelize()方法，第一个参数传入集合，第二个参数传入partition数量。Spark会为每个partition执行一个task</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().getOrCreate()</span><br><span class="line"><span class="keyword">val</span> arr = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="keyword">val</span> rdd = spark.sparkContext.parallelize(arr,<span class="number">4</span>) <span class="comment">//基于Array创建一个4分区的rdd</span></span><br></pre></td></tr></table></figure></li><li><p><strong>基于本地或HDFS文件创建RDD：使用sparkContext的textFile()方法，第一个参数传入文件路径，第二个参数传入partition数量</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().appName(<span class="string">&quot;WordCount&quot;</span>).getOrCreate()</span><br><span class="line"><span class="keyword">val</span> text = spark.sparkContext.textFile(<span class="string">&quot;/path/words.txt&quot;</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure></li></ul></li></ul><hr><h2 id="Spark中对RDD的操作有哪些？"><a href="#Spark中对RDD的操作有哪些？" class="headerlink" title="Spark中对RDD的操作有哪些？"></a>Spark中对RDD的操作有哪些？</h2><ul><li><strong>在Spark中，对RDD的操作只有两种，Transformation 和 Action</strong></li><li><strong>Transformation</strong><ul><li><strong>是对已有的RDD转化为新的RDD，如flatMap、Map等操作</strong></li><li><strong>lazy特性，在没有执行Action之前，所有的操作都只是得到一个逻辑上的RDD，内存中没有任何数据</strong></li></ul></li></ul><ul><li><strong>Action</strong><ul><li><strong>是对RDD最后的操作，如foreach，reduce，返回结果给Driver进程等操作</strong></li><li><strong>只有当执行到Action代码，才会触发之前所有的Transformation算子的执行</strong></li></ul></li></ul><hr><h2 id="Transformation算子实战"><a href="#Transformation算子实战" class="headerlink" title="Transformation算子实战"></a>Transformation算子实战</h2><p><img src="/medias/RDD%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/0.png" class="lazyload placeholder" data-srcset="/medias/RDD%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="type">SparkSession</span>.builder().getOrCreate().sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment">//map算子：集合每个元素乘2</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)).map(_ * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//filter算子：过滤集合中的偶数</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)).filter(_ % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//flatMap算子：把每行字符串拆分成单词</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;ns tql&quot;</span>,<span class="string">&quot;jk tcl&quot;</span>)).flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">//groupByKey算子：对&lt;&lt;出生地,姓名&gt;&gt;集合根据出生地分组</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;wuxi&quot;</span>,<span class="string">&quot;ns&quot;</span>),(<span class="string">&quot;shandong&quot;</span>,<span class="string">&quot;jk1&quot;</span>),(<span class="string">&quot;wuxi&quot;</span>,<span class="string">&quot;jk2&quot;</span>))).groupByKey()</span><br><span class="line"></span><br><span class="line"><span class="comment">//reduceByKey算子：对&lt;&lt;word,1&gt;&gt;集合计算每个word出现的次数</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;ns&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;jk&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;ns&quot;</span>,<span class="number">1</span>))).reduceByKey(_+_)</span><br><span class="line"></span><br><span class="line"><span class="comment">//sortByKey算子：对&lt;&lt;收入,姓名&gt;&gt;集合根据收入降序排序</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>((<span class="number">10000</span>,<span class="string">&quot;ns&quot;</span>),(<span class="number">100</span>,<span class="string">&quot;jk&quot;</span>))).sortByKey(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//join算子：对&lt;&lt;姓名，收入&gt;&gt;和&lt;&lt;姓名，出生地&gt;&gt;两个集合基于姓名进行合并</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;ns&quot;</span>,<span class="number">10000</span>),(<span class="string">&quot;jk&quot;</span>,<span class="number">100</span>)).join(sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;ns&quot;</span>,<span class="string">&quot;wuxi&quot;</span>))))</span><br><span class="line">合并结果是：<span class="type">Array</span>((<span class="string">&quot;ns&quot;</span>,(<span class="number">10000</span>,<span class="string">&quot;wuxi&quot;</span>)),(<span class="string">&quot;jk&quot;</span>,<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">//distinct算子：去除集合中重复元素</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><hr><h2 id="Action算子实战"><a href="#Action算子实战" class="headerlink" title="Action算子实战"></a>Action算子实战</h2><p><img src="/medias/RDD%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/1.png" class="lazyload placeholder" data-srcset="/medias/RDD%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="type">SparkSession</span>.builder().getOrCreate().sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment">//reduce算子：求数组元素的和</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).reduce(_+_)</span><br><span class="line"></span><br><span class="line"><span class="comment">//collect算子：返回RDD中的元素集合</span></span><br><span class="line"><span class="keyword">val</span> res = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).collect()</span><br><span class="line">返回的是：<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//take(n)算子：获取RDD中前2个元素</span></span><br><span class="line"><span class="keyword">val</span> res = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).take(<span class="number">2</span>)</span><br><span class="line">返回的是：<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//count算子：获取RDD元素个数</span></span><br><span class="line"><span class="keyword">val</span> res = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).count()</span><br><span class="line">返回的是：<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//saveAsTextFile算子：保存RDD中元素到HDFS上去</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).saveAsTextFile(<span class="string">&quot;hdfs://hdfs路径&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//countByKey算子：对计算元祖的每个Key出现的次数</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;ns&quot;</span>,<span class="number">100</span>),(<span class="string">&quot;ns&quot;</span>,<span class="number">12</span>),(<span class="string">&quot;jk&quot;</span>,<span class="number">14</span>))).countByKey()</span><br><span class="line">返回的是：(<span class="string">&quot;ns&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;jk&quot;</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//foreach算子：遍历输出RDD元素</span></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)).foreach(println(_))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;如何创建RDD？&quot;&gt;&lt;a href=&quot;#如何创建RDD？&quot; class=&quot;headerlink&quot; title=&quot;如何创建RDD？&quot;&gt;&lt;/a&gt;如何创建RDD？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;创建RDD有三种方式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
</summary>
      
    
    
    
    <category term="《Spark快速上手》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8ASpark%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>配置Spark环境及架构介绍</title>
    <link href="https://mactql.github.io/posts/4118677755.html"/>
    <id>https://mactql.github.io/posts/4118677755.html</id>
    <published>2021-09-07T07:11:00.000Z</published>
    <updated>2021-09-09T13:36:32.442Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何在IDEA中配置Spark开发环境？"><a href="#如何在IDEA中配置Spark开发环境？" class="headerlink" title="如何在IDEA中配置Spark开发环境？"></a>如何在IDEA中配置Spark开发环境？</h2><ol><li><strong>首先自行下载scala，并在IDEA中加入scala的SDK，因为spark2.4.3依赖scala2.11，故这里下载scala2.11.11</strong></li></ol><p><img src="/medias/%E9%85%8D%E7%BD%AESpark%E7%8E%AF%E5%A2%83%E5%8F%8A%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/0.png" class="lazyload placeholder" data-srcset="/medias/%E9%85%8D%E7%BD%AESpark%E7%8E%AF%E5%A2%83%E5%8F%8A%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ol start="2"><li><strong>并在pom.xml中添加spark2.4.3的依赖</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><hr><h2 id="下面介绍Spark的Standalone模式的系统架构"><a href="#下面介绍Spark的Standalone模式的系统架构" class="headerlink" title="下面介绍Spark的Standalone模式的系统架构"></a>下面介绍Spark的Standalone模式的系统架构</h2><p><img src="/medias/%E9%85%8D%E7%BD%AESpark%E7%8E%AF%E5%A2%83%E5%8F%8A%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/1.png" class="lazyload placeholder" data-srcset="/medias/%E9%85%8D%E7%BD%AESpark%E7%8E%AF%E5%A2%83%E5%8F%8A%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>上图所示即为Standalone模式架构图，下面将详细介绍</strong></li><li><strong>首先需要了解几个概念：</strong><ul><li><strong>MasterNode：该节点上常驻Master进程，负责管理全部WorkerNode</strong></li><li><strong>WorkerNode：该节点上常驻Worker进程，负责管理执行Spark任务</strong></li><li><strong>Spark作业：就是一个Spark程序，例如WordCount.scala</strong></li><li><strong>Drive进程：就是运行Spark程序中main()函数的进程</strong></li><li><strong>Executor：就是Spark计算资源的一个单位，用这个单位来占用集群资源，然后分配具体的task给Executor。在Standalone模式中，启动Executor实际上是启动图中的CoarseGrainedExecutorBackend的JVM进程</strong></li><li><strong>Task：Driver在运行main()函数时，会把一个作业拆成多个task，以线程方式在Executor执行如map算子、reduce算子。每个Executor具有多少个cpu就可以运行多少个task，如图中八个cpu两个Executor，故每个Executor可以并行运行4个task</strong></li></ul></li><li><strong>然后介绍一下流程：</strong><ol><li><strong>启动Spark集群时，Master节点会启动Master进程，Worker节点上启动Worker进程</strong></li><li><strong>接下来就提交作业给Master节点，Master节点会通知Worker节点启动Executor</strong></li><li><strong>分配task到Executor上执行，每个Executor可以执行多个task，每个task启动一个线程来执行</strong></li></ol></li><li><strong>还有一些细节：</strong><ul><li><strong>Worker进程上有一个或多个ExecutorRunner对象，每个对象可以控制一个CoarseGrainedExecutorBackend进程的启动和关闭</strong></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;如何在IDEA中配置Spark开发环境？&quot;&gt;&lt;a href=&quot;#如何在IDEA中配置Spark开发环境？&quot; class=&quot;headerlink&quot; title=&quot;如何在IDEA中配置Spark开发环境？&quot;&gt;&lt;/a&gt;如何在IDEA中配置Spark开发环境？&lt;/h2&gt;&lt;</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>初识Spark与工作原理</title>
    <link href="https://mactql.github.io/posts/2693573150.html"/>
    <id>https://mactql.github.io/posts/2693573150.html</id>
    <published>2021-09-06T06:59:00.000Z</published>
    <updated>2021-09-09T13:44:48.983Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求分析："><a href="#需求分析：" class="headerlink" title="需求分析："></a>需求分析：</h2><p><strong>读取文件所有内容，统计每个单词出现的次数</strong></p><hr><h2 id="首先介绍一下如何用Scala在本地运行WordCount"><a href="#首先介绍一下如何用Scala在本地运行WordCount" class="headerlink" title="首先介绍一下如何用Scala在本地运行WordCount"></a>首先介绍一下如何用Scala在本地运行WordCount</h2><ol><li><p><strong>第一步，首先要构建Application的运行环境，Driver创建一个SparkContext</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">conf.setAppName(<span class="string">&quot;WordCount&quot;</span>) <span class="comment">//设置作业名称</span></span><br><span class="line">.setMaster(<span class="string">&quot;local&quot;</span>) <span class="comment">//设置在本地运行</span></span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)  <span class="comment">//通过Conf参数创建一个SparkContext</span></span><br></pre></td></tr></table></figure></li><li><p><strong>第二步，加载数据并转化成RDD</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lineRDD = sc.textFile(<span class="string">&quot;HDFS路径或者磁盘文件的路径&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>第三步，对数据进行切割，把一行数据切成一个个单词</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> wordsRDD = lineRDD.flatMap(_.split(<span class="string">&quot; &quot;</span>)) <span class="comment">//flatMap使用高阶函数，这里对空格进行分割，处理后形成新的RDD</span></span><br></pre></td></tr></table></figure></li><li><p><strong>第四步，迭代words，把每个word转化成(word，1)的键值对形式</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pairRDD = wordsRDD.map((_,<span class="number">1</span>))</span><br></pre></td></tr></table></figure></li><li><p><strong>第五步，根据Key进行分组聚合统计</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> wordCountRDD = pairRDD.reduceByKey(_ + _)</span><br></pre></td></tr></table></figure></li><li><p><strong>第六步，打印结果并关闭SparkContext</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wordCountRDD.foreach(wordCount=&gt;println(wordCount._1+<span class="string">&quot;--&quot;</span>+wordCount._2))</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;需求分析：&quot;&gt;&lt;a href=&quot;#需求分析：&quot; class=&quot;headerlink&quot; title=&quot;需求分析：&quot;&gt;&lt;/a&gt;需求分析：&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;读取文件所有内容，统计每个单词出现的次数&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;首先介</summary>
      
    
    
    
    <category term="《Spark快速上手》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8ASpark%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>大数据处理框架概览</title>
    <link href="https://mactql.github.io/posts/407656541.html"/>
    <id>https://mactql.github.io/posts/407656541.html</id>
    <published>2021-09-04T06:41:00.000Z</published>
    <updated>2021-09-09T13:36:30.313Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先了解一下大数据处理框架的四层结构"><a href="#首先了解一下大数据处理框架的四层结构" class="headerlink" title="首先了解一下大数据处理框架的四层结构"></a>首先了解一下大数据处理框架的四层结构</h2><p><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/0.png" class="lazyload placeholder" data-srcset="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/0.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/1.png" class="lazyload placeholder" data-srcset="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/1.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><strong>上图所示，即大数据处理框架四层结构，下面将逐一介绍</strong></li></ul><h3 id="用户层"><a href="#用户层" class="headerlink" title="用户层"></a>用户层</h3><ul><li><strong>这一层主要是准备输入数据、Spark或Hadoop的用户代码、配置参数</strong><ul><li><strong>输入数据：一般以分块形式存在HDFS或者Hbase或数据库中</strong></li><li><strong>用户代码：这里需要了解的是，编写代码后会生成一个Driver程序，将代码提交给集群运行，如下图所示，提交Spark代码后，生成的Driver程序可以广播数据给各个task，并且收集task的运行结果</strong></li></ul></li></ul><p><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/2.png" class="lazyload placeholder" data-srcset="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/2.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></p><ul><li><p><strong>配置参数：一种是资源需求参数如资源容器数和Cpu大小等，另一种是数据流参数如数据分片大小和分片个数等见四层结构图即可</strong></p><h3 id="分布式数据并行处理层"><a href="#分布式数据并行处理层" class="headerlink" title="分布式数据并行处理层"></a>分布式数据并行处理层</h3></li><li><p><strong>这一层是把用户提交的应用转化为计算任务，然后调用下一层(资源管理与任务调度层)实现并行执行</strong></p><ul><li><strong>转化过程：MapReduce直接就map-shuffle-reduce，但是Spark不一样，如下图所示</strong></li></ul><ol><li><strong>Spark首先要把Spark代码转化为逻辑处理流程，数据处理流程包括数据单元RDD和数据依赖关系，图中每个数据单元RDD里的圆形是RDD的多个数据分片，正方形指的是输入数据分片</strong></li><li><strong>然后如图对逻辑处理流程进行划分，生成物理执行计划，包含多个stage，每个stage包含多个task，task个数一般就是RDD中数据分片的个数</strong><br><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/3.png" class="lazyload placeholder" data-srcset="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/3.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li></ol></li></ul><h3 id="资源管理与任务调度层"><a href="#资源管理与任务调度层" class="headerlink" title="资源管理与任务调度层"></a>资源管理与任务调度层</h3><ul><li><strong>这一层就是资源管理和任务调度，如下图所示</strong></li><li><strong>对于资源管理来说，Spark部署模式不同这一层的工作就不同</strong><ul><li><strong>这里仅介绍Spark的Standalone模式，其他模式后面章节会详细介绍</strong></li><li><strong>Standalone模式类似于MapReduce。区别在于MapReduce为每个task将要运行时启动一个JVM进程，而Spark是预先启动资源容器(Executor JVM)，然后在task执行时在JVM中启动task线程</strong></li></ul></li><li><strong>任务调度有两种调度器：一种是作业调度器：决定多个作业执行顺序；一种是任务调度器，决定多个task执行顺序。下图所示的是先进先出的任务调度器</strong><br><img src="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/4.png" class="lazyload placeholder" data-srcset="/medias/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E6%A6%82%E8%A7%88/4.png" srcset="https://img2.baidu.com/it/u=2037979560,2772131037&fm=26&fmt=auto&gp=0.jpg"></li></ul><h3 id="物理执行层"><a href="#物理执行层" class="headerlink" title="物理执行层"></a>物理执行层</h3><ul><li><strong>这一层就是负责启动task</strong></li><li><strong>在Spark中一个作业有很多阶段(stage)，每个stage包含很多task，每个task又对应一个JVM的的线程，一个JVM可以同时运行多个task，所以一个JVM的内存空间由多个task共享</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;首先了解一下大数据处理框架的四层结构&quot;&gt;&lt;a href=&quot;#首先了解一下大数据处理框架的四层结构&quot; class=&quot;headerlink&quot; title=&quot;首先了解一下大数据处理框架的四层结构&quot;&gt;&lt;/a&gt;首先了解一下大数据处理框架的四层结构&lt;/h2&gt;&lt;p&gt;&lt;img s</summary>
      
    
    
    
    <category term="《Apache Spark设计与实现》读书笔记" scheme="https://mactql.github.io/categories/%E3%80%8AApache-Spark%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Spark" scheme="https://mactql.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Scala高级特性</title>
    <link href="https://mactql.github.io/posts/159453455.html"/>
    <id>https://mactql.github.io/posts/159453455.html</id>
    <published>2021-09-02T08:26:00.000Z</published>
    <updated>2021-09-02T08:12:11.669Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Scala高级特性一：模式匹配"><a href="#Scala高级特性一：模式匹配" class="headerlink" title="Scala高级特性一：模式匹配"></a>Scala高级特性一：模式匹配</h2><ul><li><strong>Scala模式匹配类似于Java的switchcase，但是更加强大，甚至可以匹配变量类型、集合元素、有值没值</strong></li><li><strong>语法格式为：变量 match { case值 =&gt; 代码 }</strong><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">首先如何匹配变量类型</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">whichtype</span></span>(<span class="type">A</span>: <span class="class"><span class="keyword">type</span>)</span>&#123; <span class="comment">//匹配变量类型是否是type1、type2、type3</span></span><br><span class="line"><span class="type">A</span> <span class="keyword">match</span>&#123;</span><br><span class="line">  <span class="keyword">case</span> a:type1 =&gt; ...</span><br><span class="line">    <span class="keyword">case</span> b:type2 =&gt; ...</span><br><span class="line">    <span class="keyword">case</span> _:<span class="class"><span class="keyword">type</span>  <span class="title">=&gt;</span> ...</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如何匹配有值没值</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isNull</span></span>(<span class="type">A</span> :<span class="class"><span class="keyword">type</span>)</span>&#123;</span><br><span class="line"><span class="type">A</span> <span class="keyword">match</span>&#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">None</span> : ...</span><br><span class="line">    <span class="keyword">case</span> _ : ....</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><hr><h2 id="Scala高级特性二：隐式转换"><a href="#Scala高级特性二：隐式转换" class="headerlink" title="Scala高级特性二：隐式转换"></a>Scala高级特性二：隐式转换</h2><ul><li><strong>Scala可以在class或者object中定义隐式转换函数，定义后的对应的实例在需要时会自动转换成另一个类型的实例</strong><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//例如让狗抓老鼠</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cat</span>(<span class="params">val name:<span class="type">String</span></span>)</span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">catmouse</span></span>()&#123;...&#125; <span class="comment">//抓老鼠是cat类的函数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">Object</span> dog(<span class="keyword">val</span> name:<span class="type">String</span>)&#123;</span><br><span class="line"><span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">dogtocat</span></span>(d : dog) = <span class="keyword">new</span> <span class="type">Cat</span>()</span><br><span class="line">  <span class="keyword">new</span> dog().catmouse() <span class="comment">//因为设置了dogtocat隐式转换函数，所以会自动转换成cat并调用抓老鼠方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Scala高级特性一：模式匹配&quot;&gt;&lt;a href=&quot;#Scala高级特性一：模式匹配&quot; class=&quot;headerlink&quot; title=&quot;Scala高级特性一：模式匹配&quot;&gt;&lt;/a&gt;Scala高级特性一：模式匹配&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Scal</summary>
      
    
    
    
    <category term="《7天极速掌握Scala》课程笔记" scheme="https://mactql.github.io/categories/%E3%80%8A7%E5%A4%A9%E6%9E%81%E9%80%9F%E6%8E%8C%E6%8F%A1Scala%E3%80%8B%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Scala" scheme="https://mactql.github.io/tags/Scala/"/>
    
  </entry>
  
</feed>
